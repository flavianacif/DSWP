{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNJ82m15vqm0E+kDoyCs3+W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flavianacif/DSWP/blob/master/RFB_RN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0_YZ6IURZE_"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZX00UN5cjvM"
      },
      "source": [
        "[**Python**] - Verificar a versão do Tensorflow\n",
        "> Assegurar que está a utilizar a versão 2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THWNIk_FCe_g",
        "outputId": "1878ee27-5728-4b96-c118-be996ac9122b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZgQAKqLcLX3"
      },
      "source": [
        "[**Python**] - Definir o número de casas decimais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzKor02BCe_d"
      },
      "source": [
        "np.set_printoptions(precision= 3)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5V4KopjLWOL"
      },
      "source": [
        "### 1. Carregar os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_cwAUW3tseE"
      },
      "source": [
        "[**Python**] - Carregar os dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bs87IWPtwtm"
      },
      "source": [
        "# Leitura do dataframe:\n",
        "df_train = pd.read_csv('/train_1.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URxegHdQUD5P",
        "outputId": "8a4b42e1-7425-40b9-abb6-1a29bc89a7c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11033, 63)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBUeMtV7tzw6"
      },
      "source": [
        "[**Python**] - Mostrar as primeiras 5 linhas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcH-y4amt3gs",
        "outputId": "8c009f6d-7e0a-4254-8bc0-e9d32a3c3344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>rf2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "      <td>0.015101</td>\n",
              "      <td>0.011256</td>\n",
              "      <td>0.111095</td>\n",
              "      <td>0.003233</td>\n",
              "      <td>0.003233</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.021082</td>\n",
              "      <td>0.004541</td>\n",
              "      <td>0.004541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.130930</td>\n",
              "      <td>0.003945</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.003355</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0281</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0976</td>\n",
              "      <td>0.0333</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>0.005996</td>\n",
              "      <td>0.019476</td>\n",
              "      <td>0.124770</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010487</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.029214</td>\n",
              "      <td>0.046445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138620</td>\n",
              "      <td>0.003186</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.003355</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4167</td>\n",
              "      <td>0.4194</td>\n",
              "      <td>0.7068</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7625</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.1429</td>\n",
              "      <td>0.2857</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4444</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>74</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.002902</td>\n",
              "      <td>0.110160</td>\n",
              "      <td>0.002274</td>\n",
              "      <td>0.002274</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002902</td>\n",
              "      <td>0.020058</td>\n",
              "      <td>0.003131</td>\n",
              "      <td>0.003131</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.130405</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.014526</td>\n",
              "      <td>0.120351</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.014526</td>\n",
              "      <td>0.032017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138620</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2309</td>\n",
              "      <td>0.2309</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.1785</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.004042</td>\n",
              "      <td>0.111078</td>\n",
              "      <td>0.001121</td>\n",
              "      <td>0.001121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006063</td>\n",
              "      <td>0.023705</td>\n",
              "      <td>0.011886</td>\n",
              "      <td>0.011886</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.131285</td>\n",
              "      <td>0.001925</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.000719</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cnae2  rf2       md1       md2  ...  ind40  ind41  ind42  ind43  target\n",
              "0   0     86    1  0.015101  0.011256  ...    0.0    0.0    0.0    0.0    True\n",
              "1   1     18    9  0.005996  0.019476  ...    0.0    0.0    0.0    0.0   False\n",
              "2   2     74    9  0.000006  0.002902  ...    0.0    0.0    0.0    0.0   False\n",
              "3   3     49    4  0.000009  0.014526  ...    0.0    0.0    0.0    0.0   False\n",
              "4   4     47    1  0.000191  0.004042  ...    0.0    0.0    0.0    0.0   False\n",
              "\n",
              "[5 rows x 63 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSa161sPLcAw"
      },
      "source": [
        "### Pré-processamento e transformação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL2-6wpCuARF"
      },
      "source": [
        "[**Python**] - Construir coluna 'sexo' da seguinte forma:\n",
        "* Se Gender= 'Male' ==> sexo= 1;\n",
        "* Se Gender= 'Female' ==> sexo= 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccImSqCqDKre"
      },
      "source": [
        "def define_label(row):\n",
        "    if row['Gender'] == 'Male':\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDYamauZCq77"
      },
      "source": [
        "df_sexo['sexo'] = df_sexo.apply(lambda row: define_label(row), axis = 1)\n",
        "df_sexo.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqkOrJnNuZjg"
      },
      "source": [
        "[**Python**] - Renomear ou reescrever os nomes das colunas do dataframe em letras minúsculas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dahUMI6DsBz"
      },
      "source": [
        "df_sexo = df_sexo.drop(columns= 'Gender', axis= 1)\n",
        "df_sexo = df_sexo.rename({'Height': 'altura', 'Weight': 'peso'}, axis= 1)\n",
        "df_sexo.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTISVuZ4ukQO"
      },
      "source": [
        "[**Python**] - Definir os arrays X_sexo e y_sexo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMTIn6Zf5LlU"
      },
      "source": [
        "X = df_train.copy()\n",
        "X = X.drop(columns= ['target','id'])\n",
        "y = df_train['target'].values"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSThKwhj4LsC",
        "outputId": "d9389d08-ef31-450c-b519-4d027bd8c961",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False, False, ...,  True, False,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiO_F95jc1_s"
      },
      "source": [
        "[**Python**] - Normalizar os dados - StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOfIzZWbS4oP",
        "outputId": "73213fda-23d3-4c92-9d61-118066ecfcf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "col_num = X.select_dtypes(include=['float64']).columns\n",
        "col_num"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['md1', 'md2', 'md3', 'md4', 'md5', 'md6', 'md7', 'md8', 'md9', 'md10',\n",
              "       'md11', 'md12', 'mc1', 'mc2', 'mc3', 'mc4', 'ind01', 'ind02', 'ind03',\n",
              "       'ind04', 'ind05', 'ind06', 'ind07', 'ind08', 'ind09', 'ind10', 'ind11',\n",
              "       'ind12', 'ind13', 'ind14', 'ind15', 'ind16', 'ind17', 'ind18', 'ind19',\n",
              "       'ind20', 'ind21', 'ind22', 'ind23', 'ind24', 'ind25', 'ind26', 'ind27',\n",
              "       'ind28', 'ind29', 'ind30', 'ind31', 'ind32', 'ind33', 'ind34', 'ind35',\n",
              "       'ind36', 'ind37', 'ind38', 'ind39', 'ind40', 'ind41', 'ind42', 'ind43'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4myPAnSzE7-l",
        "outputId": "52a50b87-6045-4b7d-f92c-792f74fadfa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "SS = StandardScaler()\n",
        "\n",
        "X[col_num]= SS.fit_transform(X[col_num])\n",
        "X"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cnae2</th>\n",
              "      <th>rf2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "      <td>2.001376</td>\n",
              "      <td>0.242357</td>\n",
              "      <td>-0.596385</td>\n",
              "      <td>-0.430638</td>\n",
              "      <td>0.152674</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.428471</td>\n",
              "      <td>-0.709793</td>\n",
              "      <td>-0.461886</td>\n",
              "      <td>-0.002502</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.628558</td>\n",
              "      <td>2.134258</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.556589</td>\n",
              "      <td>2.165120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.328086</td>\n",
              "      <td>-0.735539</td>\n",
              "      <td>-0.806095</td>\n",
              "      <td>-0.842409</td>\n",
              "      <td>-0.839243</td>\n",
              "      <td>-0.707050</td>\n",
              "      <td>-0.804816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.573635</td>\n",
              "      <td>-0.596183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.673623</td>\n",
              "      <td>-1.556934</td>\n",
              "      <td>-1.247419</td>\n",
              "      <td>-1.215785</td>\n",
              "      <td>-0.764612</td>\n",
              "      <td>-0.751150</td>\n",
              "      <td>0.805421</td>\n",
              "      <td>-1.303257</td>\n",
              "      <td>-1.119314</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.701970</td>\n",
              "      <td>-0.760228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.975378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.607337</td>\n",
              "      <td>0.716694</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>0.387480</td>\n",
              "      <td>1.172213</td>\n",
              "      <td>1.430105</td>\n",
              "      <td>-0.760142</td>\n",
              "      <td>1.986368</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.579348</td>\n",
              "      <td>1.770106</td>\n",
              "      <td>-0.797393</td>\n",
              "      <td>2.028365</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.076478</td>\n",
              "      <td>1.566392</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.965044</td>\n",
              "      <td>2.165120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.664310</td>\n",
              "      <td>1.392895</td>\n",
              "      <td>0.117190</td>\n",
              "      <td>0.092460</td>\n",
              "      <td>0.655920</td>\n",
              "      <td>-0.689384</td>\n",
              "      <td>-0.787562</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.750520</td>\n",
              "      <td>-0.400652</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.540288</td>\n",
              "      <td>0.136321</td>\n",
              "      <td>0.996572</td>\n",
              "      <td>1.033080</td>\n",
              "      <td>-0.429099</td>\n",
              "      <td>-0.080470</td>\n",
              "      <td>-0.638652</td>\n",
              "      <td>-0.309639</td>\n",
              "      <td>-0.815049</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.424563</td>\n",
              "      <td>-0.760228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.025244</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.607337</td>\n",
              "      <td>-1.395295</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>74</td>\n",
              "      <td>9</td>\n",
              "      <td>-0.674382</td>\n",
              "      <td>-0.702598</td>\n",
              "      <td>-0.734921</td>\n",
              "      <td>-0.528354</td>\n",
              "      <td>-0.089710</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.777622</td>\n",
              "      <td>-0.809962</td>\n",
              "      <td>-0.566046</td>\n",
              "      <td>-0.212122</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.813056</td>\n",
              "      <td>-0.805176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.631284</td>\n",
              "      <td>-0.618950</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.664310</td>\n",
              "      <td>1.392895</td>\n",
              "      <td>1.409612</td>\n",
              "      <td>1.386654</td>\n",
              "      <td>1.276154</td>\n",
              "      <td>-0.707050</td>\n",
              "      <td>-0.804816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.573635</td>\n",
              "      <td>-0.596183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.673623</td>\n",
              "      <td>0.663728</td>\n",
              "      <td>0.996572</td>\n",
              "      <td>1.033080</td>\n",
              "      <td>1.583274</td>\n",
              "      <td>1.596347</td>\n",
              "      <td>-0.638652</td>\n",
              "      <td>1.033231</td>\n",
              "      <td>1.121589</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.424563</td>\n",
              "      <td>1.315395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.025244</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.607337</td>\n",
              "      <td>0.716694</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>49</td>\n",
              "      <td>4</td>\n",
              "      <td>-0.673864</td>\n",
              "      <td>0.612231</td>\n",
              "      <td>0.775288</td>\n",
              "      <td>-0.760142</td>\n",
              "      <td>-0.664660</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.263588</td>\n",
              "      <td>0.359384</td>\n",
              "      <td>-0.797393</td>\n",
              "      <td>-0.677702</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.076478</td>\n",
              "      <td>-0.488625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.637674</td>\n",
              "      <td>-0.702649</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.664310</td>\n",
              "      <td>-0.735539</td>\n",
              "      <td>-0.806095</td>\n",
              "      <td>-0.842409</td>\n",
              "      <td>-0.839243</td>\n",
              "      <td>-0.170321</td>\n",
              "      <td>-0.280608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.573635</td>\n",
              "      <td>-0.596183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.540288</td>\n",
              "      <td>0.663728</td>\n",
              "      <td>-0.686421</td>\n",
              "      <td>-0.653569</td>\n",
              "      <td>1.387696</td>\n",
              "      <td>1.400801</td>\n",
              "      <td>2.002404</td>\n",
              "      <td>-0.980833</td>\n",
              "      <td>-0.953238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.701970</td>\n",
              "      <td>-0.760228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.975378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.646532</td>\n",
              "      <td>0.716694</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.641563</td>\n",
              "      <td>-0.573651</td>\n",
              "      <td>-0.598885</td>\n",
              "      <td>-0.645889</td>\n",
              "      <td>-0.381256</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.494469</td>\n",
              "      <td>-0.453383</td>\n",
              "      <td>0.080827</td>\n",
              "      <td>1.089695</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.503635</td>\n",
              "      <td>0.623162</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.965044</td>\n",
              "      <td>-0.167845</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.664310</td>\n",
              "      <td>-0.735539</td>\n",
              "      <td>-0.806095</td>\n",
              "      <td>-0.842409</td>\n",
              "      <td>-0.839243</td>\n",
              "      <td>1.617460</td>\n",
              "      <td>1.465467</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.573635</td>\n",
              "      <td>-0.596183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.540288</td>\n",
              "      <td>-1.556934</td>\n",
              "      <td>-1.247419</td>\n",
              "      <td>-1.215785</td>\n",
              "      <td>-0.764612</td>\n",
              "      <td>-0.751150</td>\n",
              "      <td>-0.638652</td>\n",
              "      <td>-1.383742</td>\n",
              "      <td>-1.368303</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.701970</td>\n",
              "      <td>-0.760228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.975378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.646532</td>\n",
              "      <td>-1.395295</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11028</th>\n",
              "      <td>23</td>\n",
              "      <td>6</td>\n",
              "      <td>-0.675408</td>\n",
              "      <td>-0.894229</td>\n",
              "      <td>-0.831276</td>\n",
              "      <td>-0.760142</td>\n",
              "      <td>-0.480291</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.875267</td>\n",
              "      <td>-0.861664</td>\n",
              "      <td>-0.797393</td>\n",
              "      <td>-0.447745</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.655869</td>\n",
              "      <td>-0.530496</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.372914</td>\n",
              "      <td>-0.440151</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.827455</td>\n",
              "      <td>1.392895</td>\n",
              "      <td>1.409612</td>\n",
              "      <td>1.386654</td>\n",
              "      <td>-0.839243</td>\n",
              "      <td>-0.707050</td>\n",
              "      <td>-0.804816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.573635</td>\n",
              "      <td>0.285076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.673623</td>\n",
              "      <td>-1.556934</td>\n",
              "      <td>0.996572</td>\n",
              "      <td>1.033080</td>\n",
              "      <td>1.583274</td>\n",
              "      <td>1.596347</td>\n",
              "      <td>-0.638652</td>\n",
              "      <td>1.033231</td>\n",
              "      <td>-0.953238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.424563</td>\n",
              "      <td>-0.760228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.025244</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.607337</td>\n",
              "      <td>-1.395295</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11029</th>\n",
              "      <td>49</td>\n",
              "      <td>7</td>\n",
              "      <td>-0.674898</td>\n",
              "      <td>0.867246</td>\n",
              "      <td>1.073491</td>\n",
              "      <td>-0.145372</td>\n",
              "      <td>0.860279</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.465534</td>\n",
              "      <td>0.575905</td>\n",
              "      <td>0.113706</td>\n",
              "      <td>1.155862</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.076478</td>\n",
              "      <td>-0.077472</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.196508</td>\n",
              "      <td>1.189576</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.664310</td>\n",
              "      <td>-0.735539</td>\n",
              "      <td>-0.806095</td>\n",
              "      <td>-0.842409</td>\n",
              "      <td>-0.839243</td>\n",
              "      <td>-0.707050</td>\n",
              "      <td>-0.804816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.573635</td>\n",
              "      <td>-0.596183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.540288</td>\n",
              "      <td>-1.556934</td>\n",
              "      <td>0.622499</td>\n",
              "      <td>-0.091353</td>\n",
              "      <td>-0.764612</td>\n",
              "      <td>-0.751150</td>\n",
              "      <td>1.210827</td>\n",
              "      <td>0.831897</td>\n",
              "      <td>-0.953238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.701970</td>\n",
              "      <td>-0.760228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.975378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.646532</td>\n",
              "      <td>-1.395295</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11030</th>\n",
              "      <td>47</td>\n",
              "      <td>8</td>\n",
              "      <td>-0.674640</td>\n",
              "      <td>-0.897531</td>\n",
              "      <td>-0.833592</td>\n",
              "      <td>-0.760142</td>\n",
              "      <td>-0.664660</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.900448</td>\n",
              "      <td>-0.888663</td>\n",
              "      <td>-0.797393</td>\n",
              "      <td>-0.677702</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.685125</td>\n",
              "      <td>-0.595402</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.328911</td>\n",
              "      <td>-0.457480</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.827455</td>\n",
              "      <td>1.392895</td>\n",
              "      <td>1.409612</td>\n",
              "      <td>1.386654</td>\n",
              "      <td>1.276154</td>\n",
              "      <td>-0.707050</td>\n",
              "      <td>-0.804816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.573635</td>\n",
              "      <td>-0.596183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.673623</td>\n",
              "      <td>0.663728</td>\n",
              "      <td>0.996572</td>\n",
              "      <td>1.033080</td>\n",
              "      <td>1.583274</td>\n",
              "      <td>1.596347</td>\n",
              "      <td>-0.638652</td>\n",
              "      <td>1.033231</td>\n",
              "      <td>1.121589</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.424563</td>\n",
              "      <td>1.315395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.025244</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.607337</td>\n",
              "      <td>-1.395295</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11031</th>\n",
              "      <td>47</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.671639</td>\n",
              "      <td>-0.824839</td>\n",
              "      <td>-0.782591</td>\n",
              "      <td>-0.502884</td>\n",
              "      <td>-0.026520</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.185105</td>\n",
              "      <td>0.275238</td>\n",
              "      <td>0.588043</td>\n",
              "      <td>2.028365</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.633436</td>\n",
              "      <td>2.134258</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.965044</td>\n",
              "      <td>1.459606</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.664310</td>\n",
              "      <td>-0.735539</td>\n",
              "      <td>-0.806095</td>\n",
              "      <td>-0.842409</td>\n",
              "      <td>-0.839243</td>\n",
              "      <td>-0.707050</td>\n",
              "      <td>-0.804816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.573635</td>\n",
              "      <td>-0.596183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.673623</td>\n",
              "      <td>0.663728</td>\n",
              "      <td>-0.686421</td>\n",
              "      <td>-0.653569</td>\n",
              "      <td>-0.764612</td>\n",
              "      <td>-0.751150</td>\n",
              "      <td>2.002404</td>\n",
              "      <td>-1.182408</td>\n",
              "      <td>-1.160895</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.701970</td>\n",
              "      <td>-0.760228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.975378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.646532</td>\n",
              "      <td>-1.395295</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11032</th>\n",
              "      <td>47</td>\n",
              "      <td>8</td>\n",
              "      <td>-0.669263</td>\n",
              "      <td>-0.614327</td>\n",
              "      <td>-0.634628</td>\n",
              "      <td>-0.426715</td>\n",
              "      <td>0.154718</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.431950</td>\n",
              "      <td>1.612070</td>\n",
              "      <td>1.755000</td>\n",
              "      <td>2.028365</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.082158</td>\n",
              "      <td>1.863796</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.965044</td>\n",
              "      <td>0.486600</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.664310</td>\n",
              "      <td>-0.735539</td>\n",
              "      <td>-0.806095</td>\n",
              "      <td>-0.842409</td>\n",
              "      <td>-0.839243</td>\n",
              "      <td>-0.707050</td>\n",
              "      <td>-0.804816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.750520</td>\n",
              "      <td>1.870181</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.540288</td>\n",
              "      <td>-1.556934</td>\n",
              "      <td>-1.247419</td>\n",
              "      <td>-1.215785</td>\n",
              "      <td>1.387696</td>\n",
              "      <td>-0.359822</td>\n",
              "      <td>2.002404</td>\n",
              "      <td>-1.182408</td>\n",
              "      <td>-1.368303</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.701970</td>\n",
              "      <td>-0.760228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.975378</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.646532</td>\n",
              "      <td>0.716694</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11033 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       cnae2  rf2       md1       md2  ...  ind40  ind41  ind42  ind43\n",
              "0         86    1  2.001376  0.242357  ...    0.0    0.0    0.0    0.0\n",
              "1         18    9  0.387480  1.172213  ...    0.0    0.0    0.0    0.0\n",
              "2         74    9 -0.674382 -0.702598  ...    0.0    0.0    0.0    0.0\n",
              "3         49    4 -0.673864  0.612231  ...    0.0    0.0    0.0    0.0\n",
              "4         47    1 -0.641563 -0.573651  ...    0.0    0.0    0.0    0.0\n",
              "...      ...  ...       ...       ...  ...    ...    ...    ...    ...\n",
              "11028     23    6 -0.675408 -0.894229  ...    0.0    0.0    0.0    0.0\n",
              "11029     49    7 -0.674898  0.867246  ...    0.0    0.0    0.0    0.0\n",
              "11030     47    8 -0.674640 -0.897531  ...    0.0    0.0    0.0    0.0\n",
              "11031     47    3 -0.671639 -0.824839  ...    0.0    0.0    0.0    0.0\n",
              "11032     47    8 -0.669263 -0.614327  ...    0.0    0.0    0.0    0.0\n",
              "\n",
              "[11033 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJaJWuUqJCha"
      },
      "source": [
        "### 3. Definir as amostras de treinamento e validação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoO2iEimu4SQ"
      },
      "source": [
        "[**Python**] - Definir as amostras de treinamento e validação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTCdm-F9JBGA",
        "outputId": "fd6f3ec0-d204-48a6-f30f-13b30a3a04b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_treinamento, X_teste, y_treinamento, y_teste= train_test_split(X, y, test_size = 0.1, random_state = 20111974)\n",
        "print(f'X: Treinamento=  {X_treinamento.shape}; X: Teste=  {X_teste.shape}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: Treinamento=  (9929, 61); X: Teste=  (1104, 61)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th9CsQpB8VDK",
        "outputId": "d2d4e07e-bf08-454f-bcdd-5b420eb73ebd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'Y: Treinamento =  {y_treinamento.shape}; Y: Teste = {y_teste.shape}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y: Treinamento =  (9929,); Y: Teste = (1104,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bL-vXiULupD"
      },
      "source": [
        "### 4. Definir a arquitetura da Rede Neural com _Tensorflow_/_Keras_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxETX6dTfyU5"
      },
      "source": [
        "[**Python**] - Definir a arquitetura, ou seja:\n",
        "* $N_{I}$: Número de neurônios na camada de entrada (_Input Layer_);\n",
        "* $N_{O}$: Número de neurônios na camada de saída (_Output Layer_);\n",
        "* $N_{H}$: Número de neurônios na camada escondida (_Hidden Layer_);\n",
        "* FA: Função de ativação;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_MdsLicfyU6"
      },
      "source": [
        "# Número de Neurônios na Input Layer:\n",
        "N_I = 61\n",
        "\n",
        "# Número de neurônios na Output Layer:\n",
        "N_O = 2\n",
        "\n",
        "# Número de neurônios na Hidden Layer:\n",
        "N_H = 175\n",
        "\n",
        "N_H2 = 175\n",
        "\n",
        "# Função de Ativação da Hidden Layer:\n",
        "FA_H = tf.keras.activations.relu\n",
        "\n",
        "# Função de Ativação da Output Layer:\n",
        "FA_O = tf.keras.activations.sigmoid\n",
        "\n",
        "\n"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUMmDuPCcYyB"
      },
      "source": [
        "[**Python**] - Definir as sementes para NumPy e Tensorflow:\n",
        "> Por questões de reproducibilidade de resultados, use as sementes abaixo:\n",
        "\n",
        "* NumPy: 20111974;\n",
        "* Tensorflow: 20111974;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-echOBmceVy"
      },
      "source": [
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZceRRdinEM2"
      },
      "source": [
        "[**Python**] - Definir a Rede Neural:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXQsSYq2DBfI"
      },
      "source": [
        "* 1 camada _dropout_ com $p= 0.1$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFR5Kr_nDtD",
        "outputId": "72f75702-5a4d-4738-bc96-b3ea515e3606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "RN= Sequential()\n",
        "RN.add(Dense(N_H, input_dim= N_I, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dropout(0.1))\n",
        "RN.add(Dense(N_H2, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dropout(0.1))\n",
        "RN.add(Dense(units= N_O, activation= FA_O))\n",
        "\n",
        "# Resumo da arquitetura da Rede Neural\n",
        "print(RN.summary())"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_23 (Dense)             (None, 175)               10850     \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 175)               0         \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 175)               30800     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 175)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 2)                 352       \n",
            "=================================================================\n",
            "Total params: 42,002\n",
            "Trainable params: 42,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JBZf4ypGO8o"
      },
      "source": [
        "### 5. Compilar a Rede Neural\n",
        "\n",
        "Este é um problema de classificação binária (_Male_ ou _Female_). Portanto, temos:\n",
        "* optimizer= tf.keras.optimizers.Adam();\n",
        "* loss=  tf.keras.losses.MeanSquaredError() ou loss= tf.keras.losses.BinaryCrossentropy(). Particularmente, eu gosto de usar loss=  tf.keras.losses.MeanSquaredError() porque o resultado é mais intuitivo;\n",
        "* metrics= tf.keras.metrics.binary_accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USmAuw6f00wL"
      },
      "source": [
        "[**Python**] - Comando modelo.compile(optimizer, loss, metrics):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7KEi1_e6SSF"
      },
      "source": [
        "Algoritmo_Opt = tf.keras.optimizers.Adam()\n",
        "#Algoritmo_Opt = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
        " #   name='Adam')\n",
        "Loss_Function = tf.keras.losses.MeanSquaredError()\n",
        "Metrics_Perf = tf.keras.metrics.binary_accuracy\n",
        "\n",
        "RN.compile(optimizer = Algoritmo_Opt, loss = Loss_Function, metrics = Metrics_Perf)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc90EeV_GojX"
      },
      "source": [
        "### 6. Ajustar a Rede Neural\n",
        "\n",
        "Obs.: A opção callbacks abaixo implementa o conceito de _early stopping_. Esta opção vai parar o processo de treinamento da Rede Neural antes de atingirmos o númerco de _epochs_ quando o modelo pára de melhorar, medido pela métrica val_loss. O parâmetro _patience_= k significa que o processo de otimização vai parar se tivermos k _epochs_ consecutivas sem observarmos melhoria da performance da Rede Neural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCCTtUh_vEFP"
      },
      "source": [
        "[**Python**] - Comando modelo.fit(X_treinamento, y_treinamento, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB91J6nrF0db",
        "outputId": "a8d27ced-1c1f-42ad-c061-cf0c2589dc22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10, min_delta = 0.001)]\n",
        "hist= RN.fit(X_treinamento, y_treinamento, epochs = 100, validation_data = (X_teste, y_teste), callbacks = callbacks)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.2248 - binary_accuracy: 0.7666 - val_loss: 0.2132 - val_binary_accuracy: 0.7767\n",
            "Epoch 2/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1942 - binary_accuracy: 0.7574 - val_loss: 0.1687 - val_binary_accuracy: 0.7763\n",
            "Epoch 3/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1657 - binary_accuracy: 0.7711 - val_loss: 0.1576 - val_binary_accuracy: 0.7803\n",
            "Epoch 4/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1632 - binary_accuracy: 0.7720 - val_loss: 0.1578 - val_binary_accuracy: 0.7790\n",
            "Epoch 5/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1621 - binary_accuracy: 0.7719 - val_loss: 0.1570 - val_binary_accuracy: 0.7794\n",
            "Epoch 6/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1598 - binary_accuracy: 0.7736 - val_loss: 0.1577 - val_binary_accuracy: 0.7726\n",
            "Epoch 7/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1598 - binary_accuracy: 0.7729 - val_loss: 0.1577 - val_binary_accuracy: 0.7790\n",
            "Epoch 8/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.1581 - binary_accuracy: 0.7741 - val_loss: 0.1577 - val_binary_accuracy: 0.7754\n",
            "Epoch 9/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1570 - binary_accuracy: 0.7765 - val_loss: 0.1570 - val_binary_accuracy: 0.7803\n",
            "Epoch 10/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.1566 - binary_accuracy: 0.7765 - val_loss: 0.1563 - val_binary_accuracy: 0.7758\n",
            "Epoch 11/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.1556 - binary_accuracy: 0.7773 - val_loss: 0.1603 - val_binary_accuracy: 0.7776\n",
            "Epoch 12/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.1559 - binary_accuracy: 0.7777 - val_loss: 0.1606 - val_binary_accuracy: 0.7681\n",
            "Epoch 13/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.1543 - binary_accuracy: 0.7794 - val_loss: 0.1602 - val_binary_accuracy: 0.7713\n",
            "Epoch 14/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.1525 - binary_accuracy: 0.7826 - val_loss: 0.1562 - val_binary_accuracy: 0.7731\n",
            "Epoch 15/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.1522 - binary_accuracy: 0.7808 - val_loss: 0.1586 - val_binary_accuracy: 0.7686\n",
            "Epoch 16/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.1517 - binary_accuracy: 0.7803 - val_loss: 0.1574 - val_binary_accuracy: 0.7790\n",
            "Epoch 17/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.1496 - binary_accuracy: 0.7833 - val_loss: 0.1586 - val_binary_accuracy: 0.7790\n",
            "Epoch 18/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.1493 - binary_accuracy: 0.7865 - val_loss: 0.1585 - val_binary_accuracy: 0.7722\n",
            "Epoch 19/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.1482 - binary_accuracy: 0.7849 - val_loss: 0.1581 - val_binary_accuracy: 0.7772\n",
            "Epoch 20/100\n",
            "311/311 [==============================] - 1s 3ms/step - loss: 0.1468 - binary_accuracy: 0.7878 - val_loss: 0.1590 - val_binary_accuracy: 0.7722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9LNgeg6ci5u"
      },
      "source": [
        "def Model_Loss(hist):\n",
        "    print(hist.history.keys())\n",
        "    plt.plot(hist.history['loss'])\n",
        "    plt.plot(hist.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend(['Training', 'Validation'], loc= 'upper right')\n",
        "    plt.show()\n",
        "\n",
        "def Model_Accuracy(hist):\n",
        "    print(hist.history.keys())\n",
        "    plt.plot(hist.history['accuracy'])\n",
        "    plt.plot(hist.history['val_accuracy'])\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend(['Training', 'Validation'], loc= 'upper right')\n",
        "    plt.show()\n",
        "\n",
        "def Model_MSE(hist):\n",
        "    print(hist.history.keys())\n",
        "    plt.plot(hist.history['mse'])\n",
        "    plt.plot(hist.history['val_mse'])\n",
        "    plt.title('Model MSE')\n",
        "    plt.ylabel('MSE')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend(['Training', 'Validation'], loc= 'upper right')\n",
        "    plt.show()\n",
        "\n",
        "def Mostra_ConfusionMatrix():\n",
        "    y_pred = RN.predict_classes(X_teste)\n",
        "    mc = confusion_matrix(y_teste, y_pred)\n",
        "    #sns.heatmap(mc,annot=True, annot_kws={\"size\": 10},fmt=\"d\")\n",
        "    sns.heatmap(mc/np.sum(mc), annot=True, annot_kws={\"size\": 10}, fmt='.2%', cmap='Blues')"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71mX1iwvHMc5",
        "outputId": "e77c94f2-1005-408c-a8e8-fe9af4c6ddf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "Model_Accuracy(hist)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-52181b2ceb01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mModel_Accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-102-d8e91b2e8510>\u001b[0m in \u001b[0;36mModel_Accuracy\u001b[0;34m(hist)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mModel_Accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-zJ6GIjHbY8",
        "outputId": "53d8490e-7b98-4831-eef3-63fb5e9bbccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "Model_Loss(hist)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-8a9781df17aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mModel_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Model_Loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1sL_DTrKmpq"
      },
      "source": [
        "### 7. Avaliar a performance da Rede Neural\n",
        "\n",
        "Para avaliar a a Rede Neural, simplesmente informamos as amostras de teste: X_teste e y_teste. A função evaluate() vai retornar uma lista contendo 2 valores: loss e accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VckQfEFPvMa7"
      },
      "source": [
        "[**Python**] - Comando modelo.evaluate(X_teste, y_teste)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUhEiqxfKmpv",
        "outputId": "25c49fa4-5f27-452a-d5bb-10513a0e8ee3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "RN.evaluate(X_teste, y_teste)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1590 - binary_accuracy: 0.7722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.15897268056869507, 0.7721920013427734]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB3jYewpdYUQ",
        "outputId": "4dd069af-2b6e-4f66-f54a-892eb0b1e409",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hist2 = RN.fit(X, y, epochs = 200, callbacks = callbacks)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "326/345 [===========================>..] - ETA: 0s - loss: 0.0960 - binary_accuracy: 0.8701WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0965 - binary_accuracy: 0.8695\n",
            "Epoch 2/200\n",
            "335/345 [============================>.] - ETA: 0s - loss: 0.0944 - binary_accuracy: 0.8723WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0948 - binary_accuracy: 0.8720\n",
            "Epoch 3/200\n",
            "324/345 [===========================>..] - ETA: 0s - loss: 0.0942 - binary_accuracy: 0.8736WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0948 - binary_accuracy: 0.8717\n",
            "Epoch 4/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0956 - binary_accuracy: 0.8712WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0955 - binary_accuracy: 0.8712\n",
            "Epoch 5/200\n",
            "328/345 [===========================>..] - ETA: 0s - loss: 0.0925 - binary_accuracy: 0.8749WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0924 - binary_accuracy: 0.8755\n",
            "Epoch 6/200\n",
            "338/345 [============================>.] - ETA: 0s - loss: 0.0953 - binary_accuracy: 0.8717WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0954 - binary_accuracy: 0.8712\n",
            "Epoch 7/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0971 - binary_accuracy: 0.8684WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0970 - binary_accuracy: 0.8687\n",
            "Epoch 8/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0951 - binary_accuracy: 0.8699WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0951 - binary_accuracy: 0.8700\n",
            "Epoch 9/200\n",
            "330/345 [===========================>..] - ETA: 0s - loss: 0.0919 - binary_accuracy: 0.8752WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0922 - binary_accuracy: 0.8750\n",
            "Epoch 10/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0954 - binary_accuracy: 0.8701WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0963 - binary_accuracy: 0.8680\n",
            "Epoch 11/200\n",
            "329/345 [===========================>..] - ETA: 0s - loss: 0.0947 - binary_accuracy: 0.8710WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0949 - binary_accuracy: 0.8712\n",
            "Epoch 12/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0926 - binary_accuracy: 0.8745WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0925 - binary_accuracy: 0.8747\n",
            "Epoch 13/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0920 - binary_accuracy: 0.8765WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0920 - binary_accuracy: 0.8766\n",
            "Epoch 14/200\n",
            "333/345 [===========================>..] - ETA: 0s - loss: 0.0960 - binary_accuracy: 0.8699WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0964 - binary_accuracy: 0.8693\n",
            "Epoch 15/200\n",
            "330/345 [===========================>..] - ETA: 0s - loss: 0.0920 - binary_accuracy: 0.8783WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0921 - binary_accuracy: 0.8777\n",
            "Epoch 16/200\n",
            "328/345 [===========================>..] - ETA: 0s - loss: 0.0919 - binary_accuracy: 0.8779WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0915 - binary_accuracy: 0.8780\n",
            "Epoch 17/200\n",
            "333/345 [===========================>..] - ETA: 0s - loss: 0.0932 - binary_accuracy: 0.8749WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0928 - binary_accuracy: 0.8757\n",
            "Epoch 18/200\n",
            "336/345 [============================>.] - ETA: 0s - loss: 0.0919 - binary_accuracy: 0.8771WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0919 - binary_accuracy: 0.8766\n",
            "Epoch 19/200\n",
            "329/345 [===========================>..] - ETA: 0s - loss: 0.0927 - binary_accuracy: 0.8769WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0926 - binary_accuracy: 0.8770\n",
            "Epoch 20/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0948 - binary_accuracy: 0.8718WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0949 - binary_accuracy: 0.8717\n",
            "Epoch 21/200\n",
            "334/345 [============================>.] - ETA: 0s - loss: 0.0915 - binary_accuracy: 0.8759WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0918 - binary_accuracy: 0.8758\n",
            "Epoch 22/200\n",
            "326/345 [===========================>..] - ETA: 0s - loss: 0.0950 - binary_accuracy: 0.8699WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0947 - binary_accuracy: 0.8708\n",
            "Epoch 23/200\n",
            "325/345 [===========================>..] - ETA: 0s - loss: 0.0918 - binary_accuracy: 0.8774WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0920 - binary_accuracy: 0.8767\n",
            "Epoch 24/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0919 - binary_accuracy: 0.8753WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0918 - binary_accuracy: 0.8753\n",
            "Epoch 25/200\n",
            "324/345 [===========================>..] - ETA: 0s - loss: 0.0931 - binary_accuracy: 0.8756WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0926 - binary_accuracy: 0.8761\n",
            "Epoch 26/200\n",
            "330/345 [===========================>..] - ETA: 0s - loss: 0.0905 - binary_accuracy: 0.8788WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0902 - binary_accuracy: 0.8793\n",
            "Epoch 27/200\n",
            "338/345 [============================>.] - ETA: 0s - loss: 0.0882 - binary_accuracy: 0.8817WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0884 - binary_accuracy: 0.8815\n",
            "Epoch 28/200\n",
            "336/345 [============================>.] - ETA: 0s - loss: 0.0914 - binary_accuracy: 0.8769WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0914 - binary_accuracy: 0.8769\n",
            "Epoch 29/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0915 - binary_accuracy: 0.8745WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0919 - binary_accuracy: 0.8739\n",
            "Epoch 30/200\n",
            "342/345 [============================>.] - ETA: 0s - loss: 0.0911 - binary_accuracy: 0.8811WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0911 - binary_accuracy: 0.8812\n",
            "Epoch 31/200\n",
            "333/345 [===========================>..] - ETA: 0s - loss: 0.0899 - binary_accuracy: 0.8820WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0894 - binary_accuracy: 0.8824\n",
            "Epoch 32/200\n",
            "340/345 [============================>.] - ETA: 0s - loss: 0.0935 - binary_accuracy: 0.8744WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0933 - binary_accuracy: 0.8747\n",
            "Epoch 33/200\n",
            "325/345 [===========================>..] - ETA: 0s - loss: 0.0887 - binary_accuracy: 0.8809WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0893 - binary_accuracy: 0.8800\n",
            "Epoch 34/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0889 - binary_accuracy: 0.8791WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0894 - binary_accuracy: 0.8783\n",
            "Epoch 35/200\n",
            "321/345 [==========================>...] - ETA: 0s - loss: 0.0894 - binary_accuracy: 0.8815WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0896 - binary_accuracy: 0.8805\n",
            "Epoch 36/200\n",
            "322/345 [===========================>..] - ETA: 0s - loss: 0.0901 - binary_accuracy: 0.8780WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0897 - binary_accuracy: 0.8778\n",
            "Epoch 37/200\n",
            "331/345 [===========================>..] - ETA: 0s - loss: 0.0897 - binary_accuracy: 0.8795WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0900 - binary_accuracy: 0.8794\n",
            "Epoch 38/200\n",
            "322/345 [===========================>..] - ETA: 0s - loss: 0.0906 - binary_accuracy: 0.8786WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0902 - binary_accuracy: 0.8792\n",
            "Epoch 39/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0898 - binary_accuracy: 0.8810WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0897 - binary_accuracy: 0.8810\n",
            "Epoch 40/200\n",
            "342/345 [============================>.] - ETA: 0s - loss: 0.0906 - binary_accuracy: 0.8766WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0904 - binary_accuracy: 0.8771\n",
            "Epoch 41/200\n",
            "323/345 [===========================>..] - ETA: 0s - loss: 0.0909 - binary_accuracy: 0.8800WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0909 - binary_accuracy: 0.8790\n",
            "Epoch 42/200\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0897 - binary_accuracy: 0.8802WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0897 - binary_accuracy: 0.8802\n",
            "Epoch 43/200\n",
            "339/345 [============================>.] - ETA: 0s - loss: 0.0894 - binary_accuracy: 0.8812WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0899 - binary_accuracy: 0.8805\n",
            "Epoch 44/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0901 - binary_accuracy: 0.8790WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0902 - binary_accuracy: 0.8788\n",
            "Epoch 45/200\n",
            "337/345 [============================>.] - ETA: 0s - loss: 0.0893 - binary_accuracy: 0.8805WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0897 - binary_accuracy: 0.8799\n",
            "Epoch 46/200\n",
            "328/345 [===========================>..] - ETA: 0s - loss: 0.0882 - binary_accuracy: 0.8819WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0883 - binary_accuracy: 0.8818\n",
            "Epoch 47/200\n",
            "334/345 [============================>.] - ETA: 0s - loss: 0.0889 - binary_accuracy: 0.8818WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0892 - binary_accuracy: 0.8811\n",
            "Epoch 48/200\n",
            "325/345 [===========================>..] - ETA: 0s - loss: 0.0903 - binary_accuracy: 0.8777WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0914 - binary_accuracy: 0.8764\n",
            "Epoch 49/200\n",
            "336/345 [============================>.] - ETA: 0s - loss: 0.0891 - binary_accuracy: 0.8800WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0890 - binary_accuracy: 0.8803\n",
            "Epoch 50/200\n",
            "325/345 [===========================>..] - ETA: 0s - loss: 0.0879 - binary_accuracy: 0.8813WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0885 - binary_accuracy: 0.8801\n",
            "Epoch 51/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0878 - binary_accuracy: 0.8805WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0878 - binary_accuracy: 0.8804\n",
            "Epoch 52/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0899 - binary_accuracy: 0.8773WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0900 - binary_accuracy: 0.8773\n",
            "Epoch 53/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0896 - binary_accuracy: 0.8808WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0896 - binary_accuracy: 0.8810\n",
            "Epoch 54/200\n",
            "334/345 [============================>.] - ETA: 0s - loss: 0.0892 - binary_accuracy: 0.8802WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0893 - binary_accuracy: 0.8805\n",
            "Epoch 55/200\n",
            "334/345 [============================>.] - ETA: 0s - loss: 0.0885 - binary_accuracy: 0.8799WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0884 - binary_accuracy: 0.8801\n",
            "Epoch 56/200\n",
            "333/345 [===========================>..] - ETA: 0s - loss: 0.0852 - binary_accuracy: 0.8865WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0857 - binary_accuracy: 0.8859\n",
            "Epoch 57/200\n",
            "339/345 [============================>.] - ETA: 0s - loss: 0.0879 - binary_accuracy: 0.8822WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0878 - binary_accuracy: 0.8824\n",
            "Epoch 58/200\n",
            "331/345 [===========================>..] - ETA: 0s - loss: 0.0879 - binary_accuracy: 0.8810WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0876 - binary_accuracy: 0.8821\n",
            "Epoch 59/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0863 - binary_accuracy: 0.8860WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0864 - binary_accuracy: 0.8861\n",
            "Epoch 60/200\n",
            "338/345 [============================>.] - ETA: 0s - loss: 0.0874 - binary_accuracy: 0.8849WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0876 - binary_accuracy: 0.8847\n",
            "Epoch 61/200\n",
            "336/345 [============================>.] - ETA: 0s - loss: 0.0876 - binary_accuracy: 0.8835WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0874 - binary_accuracy: 0.8837\n",
            "Epoch 62/200\n",
            "335/345 [============================>.] - ETA: 0s - loss: 0.0850 - binary_accuracy: 0.8862WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0855 - binary_accuracy: 0.8852\n",
            "Epoch 63/200\n",
            "331/345 [===========================>..] - ETA: 0s - loss: 0.0871 - binary_accuracy: 0.8831WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0874 - binary_accuracy: 0.8829\n",
            "Epoch 64/200\n",
            "329/345 [===========================>..] - ETA: 0s - loss: 0.0860 - binary_accuracy: 0.8842WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0864 - binary_accuracy: 0.8837\n",
            "Epoch 65/200\n",
            "331/345 [===========================>..] - ETA: 0s - loss: 0.0868 - binary_accuracy: 0.8816WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0870 - binary_accuracy: 0.8814\n",
            "Epoch 66/200\n",
            "333/345 [===========================>..] - ETA: 0s - loss: 0.0852 - binary_accuracy: 0.8847WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0852 - binary_accuracy: 0.8848\n",
            "Epoch 67/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0901 - binary_accuracy: 0.8780WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0903 - binary_accuracy: 0.8776\n",
            "Epoch 68/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0874 - binary_accuracy: 0.8826WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0874 - binary_accuracy: 0.8826\n",
            "Epoch 69/200\n",
            "325/345 [===========================>..] - ETA: 0s - loss: 0.0834 - binary_accuracy: 0.8880WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0836 - binary_accuracy: 0.8876\n",
            "Epoch 70/200\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0876 - binary_accuracy: 0.8825WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0876 - binary_accuracy: 0.8825\n",
            "Epoch 71/200\n",
            "334/345 [============================>.] - ETA: 0s - loss: 0.0842 - binary_accuracy: 0.8859WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0849 - binary_accuracy: 0.8845\n",
            "Epoch 72/200\n",
            "336/345 [============================>.] - ETA: 0s - loss: 0.0851 - binary_accuracy: 0.8866WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0854 - binary_accuracy: 0.8863\n",
            "Epoch 73/200\n",
            "334/345 [============================>.] - ETA: 0s - loss: 0.0857 - binary_accuracy: 0.8860WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0858 - binary_accuracy: 0.8859\n",
            "Epoch 74/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0840 - binary_accuracy: 0.8885WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0841 - binary_accuracy: 0.8882\n",
            "Epoch 75/200\n",
            "340/345 [============================>.] - ETA: 0s - loss: 0.0865 - binary_accuracy: 0.8853WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0866 - binary_accuracy: 0.8849\n",
            "Epoch 76/200\n",
            "334/345 [============================>.] - ETA: 0s - loss: 0.0859 - binary_accuracy: 0.8851WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0853 - binary_accuracy: 0.8862\n",
            "Epoch 77/200\n",
            "342/345 [============================>.] - ETA: 0s - loss: 0.0839 - binary_accuracy: 0.8895WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0837 - binary_accuracy: 0.8896\n",
            "Epoch 78/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0845 - binary_accuracy: 0.8870WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0845 - binary_accuracy: 0.8873\n",
            "Epoch 79/200\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0857 - binary_accuracy: 0.8843WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0857 - binary_accuracy: 0.8843\n",
            "Epoch 80/200\n",
            "333/345 [===========================>..] - ETA: 0s - loss: 0.0859 - binary_accuracy: 0.8840WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0856 - binary_accuracy: 0.8844\n",
            "Epoch 81/200\n",
            "336/345 [============================>.] - ETA: 0s - loss: 0.0858 - binary_accuracy: 0.8836WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0857 - binary_accuracy: 0.8833\n",
            "Epoch 82/200\n",
            "339/345 [============================>.] - ETA: 0s - loss: 0.0857 - binary_accuracy: 0.8845WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0856 - binary_accuracy: 0.8844\n",
            "Epoch 83/200\n",
            "326/345 [===========================>..] - ETA: 0s - loss: 0.0842 - binary_accuracy: 0.8854WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0850 - binary_accuracy: 0.8844\n",
            "Epoch 84/200\n",
            "339/345 [============================>.] - ETA: 0s - loss: 0.0867 - binary_accuracy: 0.8817WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0867 - binary_accuracy: 0.8820\n",
            "Epoch 85/200\n",
            "330/345 [===========================>..] - ETA: 0s - loss: 0.0845 - binary_accuracy: 0.8869WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0848 - binary_accuracy: 0.8861\n",
            "Epoch 86/200\n",
            "328/345 [===========================>..] - ETA: 0s - loss: 0.0843 - binary_accuracy: 0.8869WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0844 - binary_accuracy: 0.8868\n",
            "Epoch 87/200\n",
            "342/345 [============================>.] - ETA: 0s - loss: 0.0857 - binary_accuracy: 0.8835WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0857 - binary_accuracy: 0.8835\n",
            "Epoch 88/200\n",
            "329/345 [===========================>..] - ETA: 0s - loss: 0.0852 - binary_accuracy: 0.8837WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0848 - binary_accuracy: 0.8842\n",
            "Epoch 89/200\n",
            "333/345 [===========================>..] - ETA: 0s - loss: 0.0853 - binary_accuracy: 0.8856WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0852 - binary_accuracy: 0.8859\n",
            "Epoch 90/200\n",
            "327/345 [===========================>..] - ETA: 0s - loss: 0.0846 - binary_accuracy: 0.8867WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0847 - binary_accuracy: 0.8865\n",
            "Epoch 91/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0834 - binary_accuracy: 0.8910WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0835 - binary_accuracy: 0.8908\n",
            "Epoch 92/200\n",
            "334/345 [============================>.] - ETA: 0s - loss: 0.0850 - binary_accuracy: 0.8854WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0855 - binary_accuracy: 0.8850\n",
            "Epoch 93/200\n",
            "331/345 [===========================>..] - ETA: 0s - loss: 0.0843 - binary_accuracy: 0.8877WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0846 - binary_accuracy: 0.8873\n",
            "Epoch 94/200\n",
            "337/345 [============================>.] - ETA: 0s - loss: 0.0867 - binary_accuracy: 0.8836WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0867 - binary_accuracy: 0.8836\n",
            "Epoch 95/200\n",
            "327/345 [===========================>..] - ETA: 0s - loss: 0.0823 - binary_accuracy: 0.8907WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0831 - binary_accuracy: 0.8897\n",
            "Epoch 96/200\n",
            "330/345 [===========================>..] - ETA: 0s - loss: 0.0836 - binary_accuracy: 0.8877WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0836 - binary_accuracy: 0.8874\n",
            "Epoch 97/200\n",
            "330/345 [===========================>..] - ETA: 0s - loss: 0.0846 - binary_accuracy: 0.8890WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0847 - binary_accuracy: 0.8888\n",
            "Epoch 98/200\n",
            "337/345 [============================>.] - ETA: 0s - loss: 0.0839 - binary_accuracy: 0.8875WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0838 - binary_accuracy: 0.8879\n",
            "Epoch 99/200\n",
            "330/345 [===========================>..] - ETA: 0s - loss: 0.0848 - binary_accuracy: 0.8840WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0849 - binary_accuracy: 0.8838\n",
            "Epoch 100/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0837 - binary_accuracy: 0.8869WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0836 - binary_accuracy: 0.8870\n",
            "Epoch 101/200\n",
            "338/345 [============================>.] - ETA: 0s - loss: 0.0868 - binary_accuracy: 0.8831WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0867 - binary_accuracy: 0.8836\n",
            "Epoch 102/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0844 - binary_accuracy: 0.8875WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0844 - binary_accuracy: 0.8876\n",
            "Epoch 103/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0860 - binary_accuracy: 0.8824WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0863 - binary_accuracy: 0.8819\n",
            "Epoch 104/200\n",
            "337/345 [============================>.] - ETA: 0s - loss: 0.0831 - binary_accuracy: 0.8897WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0839 - binary_accuracy: 0.8891\n",
            "Epoch 105/200\n",
            "330/345 [===========================>..] - ETA: 0s - loss: 0.0831 - binary_accuracy: 0.8903WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0830 - binary_accuracy: 0.8905\n",
            "Epoch 106/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0832 - binary_accuracy: 0.8879WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0832 - binary_accuracy: 0.8880\n",
            "Epoch 107/200\n",
            "336/345 [============================>.] - ETA: 0s - loss: 0.0822 - binary_accuracy: 0.8903WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0820 - binary_accuracy: 0.8905\n",
            "Epoch 108/200\n",
            "338/345 [============================>.] - ETA: 0s - loss: 0.0845 - binary_accuracy: 0.8859WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0843 - binary_accuracy: 0.8859\n",
            "Epoch 109/200\n",
            "341/345 [============================>.] - ETA: 0s - loss: 0.0860 - binary_accuracy: 0.8848WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0861 - binary_accuracy: 0.8846\n",
            "Epoch 110/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0845 - binary_accuracy: 0.8837WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0845 - binary_accuracy: 0.8838\n",
            "Epoch 111/200\n",
            "334/345 [============================>.] - ETA: 0s - loss: 0.0804 - binary_accuracy: 0.8932WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0804 - binary_accuracy: 0.8936\n",
            "Epoch 112/200\n",
            "325/345 [===========================>..] - ETA: 0s - loss: 0.0817 - binary_accuracy: 0.8911WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0824 - binary_accuracy: 0.8892\n",
            "Epoch 113/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0824 - binary_accuracy: 0.8893WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0830 - binary_accuracy: 0.8882\n",
            "Epoch 114/200\n",
            "335/345 [============================>.] - ETA: 0s - loss: 0.0829 - binary_accuracy: 0.8874WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0828 - binary_accuracy: 0.8881\n",
            "Epoch 115/200\n",
            "327/345 [===========================>..] - ETA: 0s - loss: 0.0847 - binary_accuracy: 0.8858WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0847 - binary_accuracy: 0.8861\n",
            "Epoch 116/200\n",
            "339/345 [============================>.] - ETA: 0s - loss: 0.0805 - binary_accuracy: 0.8910WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0811 - binary_accuracy: 0.8901\n",
            "Epoch 117/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0845 - binary_accuracy: 0.8885WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0853 - binary_accuracy: 0.8873\n",
            "Epoch 118/200\n",
            "341/345 [============================>.] - ETA: 0s - loss: 0.0841 - binary_accuracy: 0.8879WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0844 - binary_accuracy: 0.8872\n",
            "Epoch 119/200\n",
            "326/345 [===========================>..] - ETA: 0s - loss: 0.0816 - binary_accuracy: 0.8904WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0827 - binary_accuracy: 0.8886\n",
            "Epoch 120/200\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0840 - binary_accuracy: 0.8864WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0840 - binary_accuracy: 0.8864\n",
            "Epoch 121/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0816 - binary_accuracy: 0.8905WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0814 - binary_accuracy: 0.8908\n",
            "Epoch 122/200\n",
            "341/345 [============================>.] - ETA: 0s - loss: 0.0812 - binary_accuracy: 0.8919WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0812 - binary_accuracy: 0.8919\n",
            "Epoch 123/200\n",
            "340/345 [============================>.] - ETA: 0s - loss: 0.0810 - binary_accuracy: 0.8892WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0809 - binary_accuracy: 0.8892\n",
            "Epoch 124/200\n",
            "324/345 [===========================>..] - ETA: 0s - loss: 0.0815 - binary_accuracy: 0.8918WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0811 - binary_accuracy: 0.8925\n",
            "Epoch 125/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0820 - binary_accuracy: 0.8921WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0820 - binary_accuracy: 0.8921\n",
            "Epoch 126/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0821 - binary_accuracy: 0.8923WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0824 - binary_accuracy: 0.8920\n",
            "Epoch 127/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0795 - binary_accuracy: 0.8939WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0794 - binary_accuracy: 0.8940\n",
            "Epoch 128/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0833 - binary_accuracy: 0.8896WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0839 - binary_accuracy: 0.8894\n",
            "Epoch 129/200\n",
            "336/345 [============================>.] - ETA: 0s - loss: 0.0817 - binary_accuracy: 0.8917WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0818 - binary_accuracy: 0.8915\n",
            "Epoch 130/200\n",
            "330/345 [===========================>..] - ETA: 0s - loss: 0.0859 - binary_accuracy: 0.8835WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0856 - binary_accuracy: 0.8837\n",
            "Epoch 131/200\n",
            "340/345 [============================>.] - ETA: 0s - loss: 0.0833 - binary_accuracy: 0.8886WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0835 - binary_accuracy: 0.8882\n",
            "Epoch 132/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0841 - binary_accuracy: 0.8860WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0842 - binary_accuracy: 0.8857\n",
            "Epoch 133/200\n",
            "334/345 [============================>.] - ETA: 0s - loss: 0.0827 - binary_accuracy: 0.8896WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0827 - binary_accuracy: 0.8896\n",
            "Epoch 134/200\n",
            "342/345 [============================>.] - ETA: 0s - loss: 0.0815 - binary_accuracy: 0.8899WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0814 - binary_accuracy: 0.8901\n",
            "Epoch 135/200\n",
            "333/345 [===========================>..] - ETA: 0s - loss: 0.0792 - binary_accuracy: 0.8951WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0800 - binary_accuracy: 0.8940\n",
            "Epoch 136/200\n",
            "339/345 [============================>.] - ETA: 0s - loss: 0.0813 - binary_accuracy: 0.8912WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0815 - binary_accuracy: 0.8909\n",
            "Epoch 137/200\n",
            "336/345 [============================>.] - ETA: 0s - loss: 0.0806 - binary_accuracy: 0.8927WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0808 - binary_accuracy: 0.8923\n",
            "Epoch 138/200\n",
            "329/345 [===========================>..] - ETA: 0s - loss: 0.0832 - binary_accuracy: 0.8857WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0834 - binary_accuracy: 0.8855\n",
            "Epoch 139/200\n",
            "339/345 [============================>.] - ETA: 0s - loss: 0.0814 - binary_accuracy: 0.8913WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0814 - binary_accuracy: 0.8911\n",
            "Epoch 140/200\n",
            "327/345 [===========================>..] - ETA: 0s - loss: 0.0807 - binary_accuracy: 0.8914WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0814 - binary_accuracy: 0.8901\n",
            "Epoch 141/200\n",
            "342/345 [============================>.] - ETA: 0s - loss: 0.0805 - binary_accuracy: 0.8917WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0807 - binary_accuracy: 0.8913\n",
            "Epoch 142/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0832 - binary_accuracy: 0.8858WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0833 - binary_accuracy: 0.8858\n",
            "Epoch 143/200\n",
            "335/345 [============================>.] - ETA: 0s - loss: 0.0783 - binary_accuracy: 0.8978WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0786 - binary_accuracy: 0.8973\n",
            "Epoch 144/200\n",
            "337/345 [============================>.] - ETA: 0s - loss: 0.0820 - binary_accuracy: 0.8901WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0820 - binary_accuracy: 0.8900\n",
            "Epoch 145/200\n",
            "335/345 [============================>.] - ETA: 0s - loss: 0.0791 - binary_accuracy: 0.8963WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0793 - binary_accuracy: 0.8960\n",
            "Epoch 146/200\n",
            "340/345 [============================>.] - ETA: 0s - loss: 0.0821 - binary_accuracy: 0.8884WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0820 - binary_accuracy: 0.8886\n",
            "Epoch 147/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0821 - binary_accuracy: 0.8895WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0826 - binary_accuracy: 0.8886\n",
            "Epoch 148/200\n",
            "336/345 [============================>.] - ETA: 0s - loss: 0.0817 - binary_accuracy: 0.8896WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0818 - binary_accuracy: 0.8894\n",
            "Epoch 149/200\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0788 - binary_accuracy: 0.8947WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0788 - binary_accuracy: 0.8947\n",
            "Epoch 150/200\n",
            "336/345 [============================>.] - ETA: 0s - loss: 0.0794 - binary_accuracy: 0.8958WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0797 - binary_accuracy: 0.8951\n",
            "Epoch 151/200\n",
            "335/345 [============================>.] - ETA: 0s - loss: 0.0803 - binary_accuracy: 0.8901WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0803 - binary_accuracy: 0.8900\n",
            "Epoch 152/200\n",
            "323/345 [===========================>..] - ETA: 0s - loss: 0.0791 - binary_accuracy: 0.8951WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0804 - binary_accuracy: 0.8922\n",
            "Epoch 153/200\n",
            "330/345 [===========================>..] - ETA: 0s - loss: 0.0820 - binary_accuracy: 0.8911WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0823 - binary_accuracy: 0.8908\n",
            "Epoch 154/200\n",
            "339/345 [============================>.] - ETA: 0s - loss: 0.0803 - binary_accuracy: 0.8935WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0804 - binary_accuracy: 0.8932\n",
            "Epoch 155/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0794 - binary_accuracy: 0.8945WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0802 - binary_accuracy: 0.8931\n",
            "Epoch 156/200\n",
            "331/345 [===========================>..] - ETA: 0s - loss: 0.0783 - binary_accuracy: 0.8944WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0782 - binary_accuracy: 0.8944\n",
            "Epoch 157/200\n",
            "342/345 [============================>.] - ETA: 0s - loss: 0.0780 - binary_accuracy: 0.8981WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0781 - binary_accuracy: 0.8980\n",
            "Epoch 158/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0831 - binary_accuracy: 0.8886WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0831 - binary_accuracy: 0.8885\n",
            "Epoch 159/200\n",
            "333/345 [===========================>..] - ETA: 0s - loss: 0.0813 - binary_accuracy: 0.8903WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0818 - binary_accuracy: 0.8892\n",
            "Epoch 160/200\n",
            "336/345 [============================>.] - ETA: 0s - loss: 0.0811 - binary_accuracy: 0.8911WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0814 - binary_accuracy: 0.8908\n",
            "Epoch 161/200\n",
            "338/345 [============================>.] - ETA: 0s - loss: 0.0782 - binary_accuracy: 0.8966WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0784 - binary_accuracy: 0.8965\n",
            "Epoch 162/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0798 - binary_accuracy: 0.8920WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0803 - binary_accuracy: 0.8914\n",
            "Epoch 163/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0818 - binary_accuracy: 0.8892WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0820 - binary_accuracy: 0.8890\n",
            "Epoch 164/200\n",
            "339/345 [============================>.] - ETA: 0s - loss: 0.0811 - binary_accuracy: 0.8917WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0815 - binary_accuracy: 0.8911\n",
            "Epoch 165/200\n",
            "340/345 [============================>.] - ETA: 0s - loss: 0.0809 - binary_accuracy: 0.8919WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0810 - binary_accuracy: 0.8921\n",
            "Epoch 166/200\n",
            "326/345 [===========================>..] - ETA: 0s - loss: 0.0807 - binary_accuracy: 0.8904WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0812 - binary_accuracy: 0.8904\n",
            "Epoch 167/200\n",
            "341/345 [============================>.] - ETA: 0s - loss: 0.0815 - binary_accuracy: 0.8915WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0815 - binary_accuracy: 0.8915\n",
            "Epoch 168/200\n",
            "339/345 [============================>.] - ETA: 0s - loss: 0.0775 - binary_accuracy: 0.8976WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0774 - binary_accuracy: 0.8977\n",
            "Epoch 169/200\n",
            "343/345 [============================>.] - ETA: 0s - loss: 0.0803 - binary_accuracy: 0.8908WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0802 - binary_accuracy: 0.8908\n",
            "Epoch 170/200\n",
            "342/345 [============================>.] - ETA: 0s - loss: 0.0821 - binary_accuracy: 0.8882WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0822 - binary_accuracy: 0.8880\n",
            "Epoch 171/200\n",
            "325/345 [===========================>..] - ETA: 0s - loss: 0.0810 - binary_accuracy: 0.8931WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0818 - binary_accuracy: 0.8918\n",
            "Epoch 172/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0815 - binary_accuracy: 0.8920WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0821 - binary_accuracy: 0.8910\n",
            "Epoch 173/200\n",
            "331/345 [===========================>..] - ETA: 0s - loss: 0.0806 - binary_accuracy: 0.8922WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0810 - binary_accuracy: 0.8921\n",
            "Epoch 174/200\n",
            "339/345 [============================>.] - ETA: 0s - loss: 0.0782 - binary_accuracy: 0.8967WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0785 - binary_accuracy: 0.8959\n",
            "Epoch 175/200\n",
            "324/345 [===========================>..] - ETA: 0s - loss: 0.0787 - binary_accuracy: 0.8954WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0787 - binary_accuracy: 0.8950\n",
            "Epoch 176/200\n",
            "326/345 [===========================>..] - ETA: 0s - loss: 0.0817 - binary_accuracy: 0.8895WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0819 - binary_accuracy: 0.8892\n",
            "Epoch 177/200\n",
            "330/345 [===========================>..] - ETA: 0s - loss: 0.0790 - binary_accuracy: 0.8940WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0790 - binary_accuracy: 0.8937\n",
            "Epoch 178/200\n",
            "333/345 [===========================>..] - ETA: 0s - loss: 0.0794 - binary_accuracy: 0.8951WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0798 - binary_accuracy: 0.8943\n",
            "Epoch 179/200\n",
            "325/345 [===========================>..] - ETA: 0s - loss: 0.0799 - binary_accuracy: 0.8928WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0798 - binary_accuracy: 0.8928\n",
            "Epoch 180/200\n",
            "333/345 [===========================>..] - ETA: 0s - loss: 0.0780 - binary_accuracy: 0.8971WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0780 - binary_accuracy: 0.8971\n",
            "Epoch 181/200\n",
            "323/345 [===========================>..] - ETA: 0s - loss: 0.0791 - binary_accuracy: 0.8937WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0798 - binary_accuracy: 0.8923\n",
            "Epoch 182/200\n",
            "329/345 [===========================>..] - ETA: 0s - loss: 0.0804 - binary_accuracy: 0.8916WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0807 - binary_accuracy: 0.8911\n",
            "Epoch 183/200\n",
            "328/345 [===========================>..] - ETA: 0s - loss: 0.0827 - binary_accuracy: 0.8916WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0829 - binary_accuracy: 0.8913\n",
            "Epoch 184/200\n",
            "330/345 [===========================>..] - ETA: 0s - loss: 0.0832 - binary_accuracy: 0.8889WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0829 - binary_accuracy: 0.8894\n",
            "Epoch 185/200\n",
            "337/345 [============================>.] - ETA: 0s - loss: 0.0795 - binary_accuracy: 0.8953WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0802 - binary_accuracy: 0.8943\n",
            "Epoch 186/200\n",
            "339/345 [============================>.] - ETA: 0s - loss: 0.0799 - binary_accuracy: 0.8925WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0801 - binary_accuracy: 0.8925\n",
            "Epoch 187/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0778 - binary_accuracy: 0.8972WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0780 - binary_accuracy: 0.8969\n",
            "Epoch 188/200\n",
            "337/345 [============================>.] - ETA: 0s - loss: 0.0802 - binary_accuracy: 0.8922WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0801 - binary_accuracy: 0.8923\n",
            "Epoch 189/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0775 - binary_accuracy: 0.8987WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0784 - binary_accuracy: 0.8974\n",
            "Epoch 190/200\n",
            "327/345 [===========================>..] - ETA: 0s - loss: 0.0792 - binary_accuracy: 0.8950WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0785 - binary_accuracy: 0.8962\n",
            "Epoch 191/200\n",
            "338/345 [============================>.] - ETA: 0s - loss: 0.0762 - binary_accuracy: 0.8999WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0763 - binary_accuracy: 0.8996\n",
            "Epoch 192/200\n",
            "328/345 [===========================>..] - ETA: 0s - loss: 0.0778 - binary_accuracy: 0.8972WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0785 - binary_accuracy: 0.8959\n",
            "Epoch 193/200\n",
            "344/345 [============================>.] - ETA: 0s - loss: 0.0786 - binary_accuracy: 0.8941WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0785 - binary_accuracy: 0.8943\n",
            "Epoch 194/200\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0823 - binary_accuracy: 0.8893WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0823 - binary_accuracy: 0.8893\n",
            "Epoch 195/200\n",
            "341/345 [============================>.] - ETA: 0s - loss: 0.0789 - binary_accuracy: 0.8936WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0789 - binary_accuracy: 0.8935\n",
            "Epoch 196/200\n",
            "338/345 [============================>.] - ETA: 0s - loss: 0.0796 - binary_accuracy: 0.8963WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0795 - binary_accuracy: 0.8965\n",
            "Epoch 197/200\n",
            "342/345 [============================>.] - ETA: 0s - loss: 0.0828 - binary_accuracy: 0.8911WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0825 - binary_accuracy: 0.8915\n",
            "Epoch 198/200\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0782 - binary_accuracy: 0.8930WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0782 - binary_accuracy: 0.8930\n",
            "Epoch 199/200\n",
            "332/345 [===========================>..] - ETA: 0s - loss: 0.0776 - binary_accuracy: 0.8960WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 2ms/step - loss: 0.0785 - binary_accuracy: 0.8947\n",
            "Epoch 200/200\n",
            "326/345 [===========================>..] - ETA: 0s - loss: 0.0778 - binary_accuracy: 0.8993WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,binary_accuracy\n",
            "345/345 [==============================] - 1s 3ms/step - loss: 0.0783 - binary_accuracy: 0.8988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiM_zEX6epou",
        "outputId": "eb4687be-91f4-4a7f-c3c4-a81f6585bc7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "RN.evaluate(X, y)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "345/345 [==============================] - 0s 1ms/step - loss: 0.0601 - binary_accuracy: 0.9244\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.060104962438344955, 0.9244086146354675]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agO4cGTqKmpz"
      },
      "source": [
        "A seguir, a matriz de confusão:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdiMhkVyaCDS"
      },
      "source": [
        "def Mostra_ConfusionMatrix():\n",
        "    y_pred = RN.predict_classes(X)\n",
        "    mc = confusion_matrix(y, y_pred)\n",
        "    #sns.heatmap(mc,annot=True, annot_kws={\"size\": 10},fmt=\"d\")\n",
        "    sns.heatmap(mc/np.sum(mc), annot=True, annot_kws={\"size\": 10}, fmt='.2%', cmap='Blues')"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLIAXu7SN7pV",
        "outputId": "e0464472-1fc1-4930-d839-564eeff37c1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "Mostra_ConfusionMatrix()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5zYHcGuMPZe"
      },
      "source": [
        "### 8. _Fine tuning_ da Rede Neural\n",
        "\n",
        "Para aumentar a acurácia da Rede Neural, sugiro aumentarmos o número de neurônios na _Hidden Layer_ e/ou aumentar o número de _Hidden Layers_.\n",
        "\n",
        "No entanto, obtivemos uma acurácia razoável com a Rede Neural _baseline_. Portanto, deixo como exercício para os alunos o desafio de melhorar a acurácia desta Rede Neural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ISodOu-Kmp3"
      },
      "source": [
        "### 9. Fazer Predições com a Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xgdL1W4vUrN"
      },
      "source": [
        "[**Python**] - Comando:\n",
        "* RN.predict_classes(X_treinamento);\n",
        "* RN.predict_classes(X_teste)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qun1-vOKmp4",
        "outputId": "5e6acced-fe31-4638-b629-26731a32c8aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = RN.predict_classes(X)\n",
        "y_pred[:10]"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7sRwTWGKmp8",
        "outputId": "b0cd33f3-8229-45de-bef8-ea4ceaab51da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_teste[:10]"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False,  True, False,  True, False, False,\n",
              "        True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOIfNJKEhUM3",
        "outputId": "7f5d1177-1dd8-45cb-c08b-334b1f9ef673",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dif = 1 - ((abs(y - y_pred).sum())/len(y))\n",
        "dif"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5605003172301277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jG1e5A-GffMd"
      },
      "source": [
        "df_test = pd.read_csv('/test_1.csv')"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jdL1-azgE1W"
      },
      "source": [
        "X_teste = df_test.drop(columns = ['id'], axis = 1)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1mD3H9Gf5PH",
        "outputId": "90bd37c8-4937-42e7-a95b-c2c743350379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>rf2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md6</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md11</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc2</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind01</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind09</th>\n",
              "      <th>ind10</th>\n",
              "      <th>ind11</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind14</th>\n",
              "      <th>ind15</th>\n",
              "      <th>ind16</th>\n",
              "      <th>ind17</th>\n",
              "      <th>ind18</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind28</th>\n",
              "      <th>ind29</th>\n",
              "      <th>ind30</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind33</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind35</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>ind38</th>\n",
              "      <th>ind39</th>\n",
              "      <th>ind40</th>\n",
              "      <th>ind41</th>\n",
              "      <th>ind42</th>\n",
              "      <th>ind43</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3411</td>\n",
              "      <td>71</td>\n",
              "      <td>6</td>\n",
              "      <td>0.015101</td>\n",
              "      <td>0.004743</td>\n",
              "      <td>0.111771</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005432</td>\n",
              "      <td>0.023085</td>\n",
              "      <td>0.009890</td>\n",
              "      <td>0.011346</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.131320</td>\n",
              "      <td>0.000176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.442161e-09</td>\n",
              "      <td>0.000917</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2177</td>\n",
              "      <td>86</td>\n",
              "      <td>8</td>\n",
              "      <td>0.012269</td>\n",
              "      <td>0.005919</td>\n",
              "      <td>0.111803</td>\n",
              "      <td>0.001136</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006160</td>\n",
              "      <td>0.022035</td>\n",
              "      <td>0.001686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.132734</td>\n",
              "      <td>0.003945</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.343705e-06</td>\n",
              "      <td>0.001462</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.36075</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8400</td>\n",
              "      <td>41</td>\n",
              "      <td>9</td>\n",
              "      <td>0.002325</td>\n",
              "      <td>0.001882</td>\n",
              "      <td>0.109870</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002823</td>\n",
              "      <td>0.020522</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.131390</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.473043e-05</td>\n",
              "      <td>0.000659</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>464</td>\n",
              "      <td>58</td>\n",
              "      <td>9</td>\n",
              "      <td>0.015101</td>\n",
              "      <td>0.028263</td>\n",
              "      <td>0.129650</td>\n",
              "      <td>0.028248</td>\n",
              "      <td>0.005284</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036084</td>\n",
              "      <td>0.050898</td>\n",
              "      <td>0.040644</td>\n",
              "      <td>0.004436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.138620</td>\n",
              "      <td>0.003389</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.104422e-03</td>\n",
              "      <td>0.003108</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.4810</td>\n",
              "      <td>0.8654</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.19260</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8694</td>\n",
              "      <td>0.9212</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1785</td>\n",
              "      <td>0.1389</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6672</td>\n",
              "      <td>86</td>\n",
              "      <td>3</td>\n",
              "      <td>0.011190</td>\n",
              "      <td>0.004536</td>\n",
              "      <td>0.110678</td>\n",
              "      <td>0.002873</td>\n",
              "      <td>0.003131</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004536</td>\n",
              "      <td>0.020658</td>\n",
              "      <td>0.003853</td>\n",
              "      <td>0.004202</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.130692</td>\n",
              "      <td>0.000763</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0153</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7799</td>\n",
              "      <td>0.7799</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id  cnae2  rf2       md1       md2  ...  ind39  ind40  ind41  ind42  ind43\n",
              "0  3411     71    6  0.015101  0.004743  ...    0.0    0.0    0.0    0.0    0.0\n",
              "1  2177     86    8  0.012269  0.005919  ...    0.0    0.0    0.0    0.0    0.0\n",
              "2  8400     41    9  0.002325  0.001882  ...    0.0    0.0    0.0    0.0    0.0\n",
              "3   464     58    9  0.015101  0.028263  ...    0.0    0.0    0.0    0.0    0.0\n",
              "4  6672     86    3  0.011190  0.004536  ...    0.0    0.0    0.0    0.0    0.0\n",
              "\n",
              "[5 rows x 62 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqy2rt3YfPiy"
      },
      "source": [
        "y_teste = RN.predict_classes(X_teste)\n",
        "\n",
        "df_submit = pd.DataFrame(zip(df_test['id'],y_teste), columns = ['id','target'])\n",
        "\n",
        "df_submit.to_csv('/PyLadies_NL.csv',index = False, sep = ',')"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C_u02mygKgt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU_6XlFRgPL2",
        "outputId": "9d84cec9-19c7-4b1f-c5c7-feeb9c4f70a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_submit['target'].value_counts()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    794\n",
              "1    206\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvywP0nZMtA-"
      },
      "source": [
        "### 10. Conclusões\n",
        "\n",
        "Desenvolvemos uma Rede Neural capaz de identificar Sexo (_Gender_) com acurácia= 0.9120."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL2g2pn-RfJi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
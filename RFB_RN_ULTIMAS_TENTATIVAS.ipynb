{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO57PjHZKE23sSHq8SX+tOF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flavianacif/DSWP/blob/master/RFB_RN_ULTIMAS_TENTATIVAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0_YZ6IURZE_"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZX00UN5cjvM"
      },
      "source": [
        "[**Python**] - Verificar a versão do Tensorflow\n",
        "> Assegurar que está a utilizar a versão 2.x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THWNIk_FCe_g",
        "outputId": "1878ee27-5728-4b96-c118-be996ac9122b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZgQAKqLcLX3"
      },
      "source": [
        "[**Python**] - Definir o número de casas decimais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzKor02BCe_d"
      },
      "source": [
        "np.set_printoptions(precision= 3)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5V4KopjLWOL"
      },
      "source": [
        "### 1. Carregar os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_cwAUW3tseE"
      },
      "source": [
        "[**Python**] - Carregar os dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Bs87IWPtwtm"
      },
      "source": [
        "# Leitura do dataframe:\n",
        "df_train = pd.read_csv('/train_6.csv')"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gYa3Hy6lrZi"
      },
      "source": [
        "df_X = df_train.copy()"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI8BYLNpr__x"
      },
      "source": [
        "df_test = pd.read_csv('/test_6.csv')"
      ],
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URxegHdQUD5P",
        "outputId": "e444bf57-4c37-443c-93d8-621cc596513b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11033, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noCEzzI-mJPc",
        "outputId": "20fdf5e1-bb7f-4e46-b689-52319dbbb5fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>cnae2_0</th>\n",
              "      <th>cnae2_1</th>\n",
              "      <th>cnae2_2</th>\n",
              "      <th>...</th>\n",
              "      <th>cnae2_60</th>\n",
              "      <th>cnae2_61</th>\n",
              "      <th>cnae2_62</th>\n",
              "      <th>cnae2_63</th>\n",
              "      <th>cnae2_64</th>\n",
              "      <th>cnae2_65</th>\n",
              "      <th>cnae2_66</th>\n",
              "      <th>cnae2_68</th>\n",
              "      <th>cnae2_69</th>\n",
              "      <th>cnae2_70</th>\n",
              "      <th>cnae2_71</th>\n",
              "      <th>cnae2_72</th>\n",
              "      <th>cnae2_73</th>\n",
              "      <th>cnae2_74</th>\n",
              "      <th>cnae2_75</th>\n",
              "      <th>cnae2_77</th>\n",
              "      <th>cnae2_78</th>\n",
              "      <th>cnae2_79</th>\n",
              "      <th>cnae2_80</th>\n",
              "      <th>cnae2_81</th>\n",
              "      <th>cnae2_82</th>\n",
              "      <th>cnae2_85</th>\n",
              "      <th>cnae2_86</th>\n",
              "      <th>cnae2_87</th>\n",
              "      <th>cnae2_90</th>\n",
              "      <th>cnae2_91</th>\n",
              "      <th>cnae2_93</th>\n",
              "      <th>cnae2_94</th>\n",
              "      <th>cnae2_95</th>\n",
              "      <th>cnae2_96</th>\n",
              "      <th>rf2_0</th>\n",
              "      <th>rf2_1</th>\n",
              "      <th>rf2_2</th>\n",
              "      <th>rf2_3</th>\n",
              "      <th>rf2_4</th>\n",
              "      <th>rf2_5</th>\n",
              "      <th>rf2_6</th>\n",
              "      <th>rf2_7</th>\n",
              "      <th>rf2_8</th>\n",
              "      <th>rf2_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3411</td>\n",
              "      <td>2.003680</td>\n",
              "      <td>-0.494787</td>\n",
              "      <td>-0.495820</td>\n",
              "      <td>-0.442070</td>\n",
              "      <td>0.123285</td>\n",
              "      <td>-0.551138</td>\n",
              "      <td>-0.513523</td>\n",
              "      <td>-0.065299</td>\n",
              "      <td>1.010537</td>\n",
              "      <td>-0.488845</td>\n",
              "      <td>-0.691012</td>\n",
              "      <td>-0.677706</td>\n",
              "      <td>0.001520</td>\n",
              "      <td>-0.272616</td>\n",
              "      <td>-0.732025</td>\n",
              "      <td>1.415327</td>\n",
              "      <td>1.391831</td>\n",
              "      <td>-0.833054</td>\n",
              "      <td>-0.712381</td>\n",
              "      <td>-0.810896</td>\n",
              "      <td>-0.577874</td>\n",
              "      <td>-0.598610</td>\n",
              "      <td>-1.536467</td>\n",
              "      <td>-1.553749</td>\n",
              "      <td>0.437683</td>\n",
              "      <td>0.471211</td>\n",
              "      <td>1.586372</td>\n",
              "      <td>1.598694</td>\n",
              "      <td>0.284143</td>\n",
              "      <td>-1.378361</td>\n",
              "      <td>-1.365289</td>\n",
              "      <td>-0.698925</td>\n",
              "      <td>-0.753537</td>\n",
              "      <td>-0.970113</td>\n",
              "      <td>0.607919</td>\n",
              "      <td>-1.389713</td>\n",
              "      <td>-0.012893</td>\n",
              "      <td>-0.087294</td>\n",
              "      <td>-0.049994</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054779</td>\n",
              "      <td>-0.038706</td>\n",
              "      <td>-0.119351</td>\n",
              "      <td>-0.045628</td>\n",
              "      <td>-0.117548</td>\n",
              "      <td>-0.027359</td>\n",
              "      <td>-0.092003</td>\n",
              "      <td>-0.202279</td>\n",
              "      <td>-0.155474</td>\n",
              "      <td>-0.130995</td>\n",
              "      <td>5.337850</td>\n",
              "      <td>-0.024126</td>\n",
              "      <td>-0.118993</td>\n",
              "      <td>-0.100786</td>\n",
              "      <td>-0.025793</td>\n",
              "      <td>-0.108889</td>\n",
              "      <td>-0.098661</td>\n",
              "      <td>-0.041812</td>\n",
              "      <td>-0.075387</td>\n",
              "      <td>-0.120421</td>\n",
              "      <td>-0.153217</td>\n",
              "      <td>-0.109667</td>\n",
              "      <td>-0.292440</td>\n",
              "      <td>-0.037614</td>\n",
              "      <td>-0.056285</td>\n",
              "      <td>-0.009117</td>\n",
              "      <td>-0.043762</td>\n",
              "      <td>-0.031595</td>\n",
              "      <td>-0.039768</td>\n",
              "      <td>-0.05244</td>\n",
              "      <td>-0.27917</td>\n",
              "      <td>-0.289247</td>\n",
              "      <td>-0.338801</td>\n",
              "      <td>-0.257087</td>\n",
              "      <td>-0.244164</td>\n",
              "      <td>-0.289247</td>\n",
              "      <td>2.648897</td>\n",
              "      <td>-0.228481</td>\n",
              "      <td>-0.290089</td>\n",
              "      <td>-0.654796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2177</td>\n",
              "      <td>1.500909</td>\n",
              "      <td>-0.361906</td>\n",
              "      <td>-0.491025</td>\n",
              "      <td>-0.644654</td>\n",
              "      <td>-0.664717</td>\n",
              "      <td>-0.485928</td>\n",
              "      <td>-0.616134</td>\n",
              "      <td>-0.672111</td>\n",
              "      <td>-0.676531</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>2.117592</td>\n",
              "      <td>-0.670669</td>\n",
              "      <td>0.482933</td>\n",
              "      <td>-0.501580</td>\n",
              "      <td>-0.732025</td>\n",
              "      <td>-0.802706</td>\n",
              "      <td>-0.839223</td>\n",
              "      <td>1.286482</td>\n",
              "      <td>1.605530</td>\n",
              "      <td>1.455495</td>\n",
              "      <td>1.737508</td>\n",
              "      <td>1.864395</td>\n",
              "      <td>-1.536467</td>\n",
              "      <td>-1.553749</td>\n",
              "      <td>0.998441</td>\n",
              "      <td>-1.214927</td>\n",
              "      <td>-0.763882</td>\n",
              "      <td>-0.750870</td>\n",
              "      <td>-0.640278</td>\n",
              "      <td>1.036880</td>\n",
              "      <td>1.124830</td>\n",
              "      <td>-0.698925</td>\n",
              "      <td>1.327075</td>\n",
              "      <td>-0.970113</td>\n",
              "      <td>-1.644957</td>\n",
              "      <td>0.719573</td>\n",
              "      <td>-0.012893</td>\n",
              "      <td>-0.087294</td>\n",
              "      <td>-0.049994</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054779</td>\n",
              "      <td>-0.038706</td>\n",
              "      <td>-0.119351</td>\n",
              "      <td>-0.045628</td>\n",
              "      <td>-0.117548</td>\n",
              "      <td>-0.027359</td>\n",
              "      <td>-0.092003</td>\n",
              "      <td>-0.202279</td>\n",
              "      <td>-0.155474</td>\n",
              "      <td>-0.130995</td>\n",
              "      <td>-0.187341</td>\n",
              "      <td>-0.024126</td>\n",
              "      <td>-0.118993</td>\n",
              "      <td>-0.100786</td>\n",
              "      <td>-0.025793</td>\n",
              "      <td>-0.108889</td>\n",
              "      <td>-0.098661</td>\n",
              "      <td>-0.041812</td>\n",
              "      <td>-0.075387</td>\n",
              "      <td>-0.120421</td>\n",
              "      <td>-0.153217</td>\n",
              "      <td>-0.109667</td>\n",
              "      <td>3.419508</td>\n",
              "      <td>-0.037614</td>\n",
              "      <td>-0.056285</td>\n",
              "      <td>-0.009117</td>\n",
              "      <td>-0.043762</td>\n",
              "      <td>-0.031595</td>\n",
              "      <td>-0.039768</td>\n",
              "      <td>-0.05244</td>\n",
              "      <td>-0.27917</td>\n",
              "      <td>-0.289247</td>\n",
              "      <td>-0.338801</td>\n",
              "      <td>-0.257087</td>\n",
              "      <td>-0.244164</td>\n",
              "      <td>-0.289247</td>\n",
              "      <td>-0.377516</td>\n",
              "      <td>-0.228481</td>\n",
              "      <td>3.447216</td>\n",
              "      <td>-0.654796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8400</td>\n",
              "      <td>-0.264478</td>\n",
              "      <td>-0.818245</td>\n",
              "      <td>-0.777297</td>\n",
              "      <td>-0.760530</td>\n",
              "      <td>-0.664717</td>\n",
              "      <td>-0.784815</td>\n",
              "      <td>-0.764148</td>\n",
              "      <td>-0.796796</td>\n",
              "      <td>-0.676531</td>\n",
              "      <td>-0.464045</td>\n",
              "      <td>-0.668474</td>\n",
              "      <td>-0.614676</td>\n",
              "      <td>-0.226717</td>\n",
              "      <td>-0.138354</td>\n",
              "      <td>-0.732025</td>\n",
              "      <td>1.415327</td>\n",
              "      <td>1.391831</td>\n",
              "      <td>1.286482</td>\n",
              "      <td>-0.712381</td>\n",
              "      <td>-0.810896</td>\n",
              "      <td>-0.577874</td>\n",
              "      <td>-0.598610</td>\n",
              "      <td>0.675043</td>\n",
              "      <td>0.664488</td>\n",
              "      <td>-1.244591</td>\n",
              "      <td>-1.214927</td>\n",
              "      <td>1.586372</td>\n",
              "      <td>1.598694</td>\n",
              "      <td>-0.640278</td>\n",
              "      <td>1.036880</td>\n",
              "      <td>1.124830</td>\n",
              "      <td>-0.698925</td>\n",
              "      <td>1.327075</td>\n",
              "      <td>1.030808</td>\n",
              "      <td>0.607919</td>\n",
              "      <td>0.719573</td>\n",
              "      <td>-0.012893</td>\n",
              "      <td>-0.087294</td>\n",
              "      <td>-0.049994</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054779</td>\n",
              "      <td>-0.038706</td>\n",
              "      <td>-0.119351</td>\n",
              "      <td>-0.045628</td>\n",
              "      <td>-0.117548</td>\n",
              "      <td>-0.027359</td>\n",
              "      <td>-0.092003</td>\n",
              "      <td>-0.202279</td>\n",
              "      <td>-0.155474</td>\n",
              "      <td>-0.130995</td>\n",
              "      <td>-0.187341</td>\n",
              "      <td>-0.024126</td>\n",
              "      <td>-0.118993</td>\n",
              "      <td>-0.100786</td>\n",
              "      <td>-0.025793</td>\n",
              "      <td>-0.108889</td>\n",
              "      <td>-0.098661</td>\n",
              "      <td>-0.041812</td>\n",
              "      <td>-0.075387</td>\n",
              "      <td>-0.120421</td>\n",
              "      <td>-0.153217</td>\n",
              "      <td>-0.109667</td>\n",
              "      <td>-0.292440</td>\n",
              "      <td>-0.037614</td>\n",
              "      <td>-0.056285</td>\n",
              "      <td>-0.009117</td>\n",
              "      <td>-0.043762</td>\n",
              "      <td>-0.031595</td>\n",
              "      <td>-0.039768</td>\n",
              "      <td>-0.05244</td>\n",
              "      <td>-0.27917</td>\n",
              "      <td>-0.289247</td>\n",
              "      <td>-0.338801</td>\n",
              "      <td>-0.257087</td>\n",
              "      <td>-0.244164</td>\n",
              "      <td>-0.289247</td>\n",
              "      <td>-0.377516</td>\n",
              "      <td>-0.228481</td>\n",
              "      <td>-0.290089</td>\n",
              "      <td>1.527193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>464</td>\n",
              "      <td>2.003680</td>\n",
              "      <td>2.163904</td>\n",
              "      <td>2.152560</td>\n",
              "      <td>2.121936</td>\n",
              "      <td>0.669432</td>\n",
              "      <td>2.194291</td>\n",
              "      <td>2.206491</td>\n",
              "      <td>2.209243</td>\n",
              "      <td>-0.016854</td>\n",
              "      <td>2.080461</td>\n",
              "      <td>1.703231</td>\n",
              "      <td>0.253817</td>\n",
              "      <td>1.936345</td>\n",
              "      <td>-0.663413</td>\n",
              "      <td>-0.732025</td>\n",
              "      <td>-0.802706</td>\n",
              "      <td>-0.839223</td>\n",
              "      <td>-0.833054</td>\n",
              "      <td>0.402534</td>\n",
              "      <td>1.150439</td>\n",
              "      <td>1.737508</td>\n",
              "      <td>0.716358</td>\n",
              "      <td>0.386219</td>\n",
              "      <td>0.489691</td>\n",
              "      <td>0.437683</td>\n",
              "      <td>0.471211</td>\n",
              "      <td>-0.763882</td>\n",
              "      <td>-0.750870</td>\n",
              "      <td>1.999869</td>\n",
              "      <td>-1.042884</td>\n",
              "      <td>-0.120230</td>\n",
              "      <td>-0.698925</td>\n",
              "      <td>-0.753537</td>\n",
              "      <td>-0.970113</td>\n",
              "      <td>-1.644957</td>\n",
              "      <td>-1.389713</td>\n",
              "      <td>-0.012893</td>\n",
              "      <td>-0.087294</td>\n",
              "      <td>-0.049994</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054779</td>\n",
              "      <td>-0.038706</td>\n",
              "      <td>-0.119351</td>\n",
              "      <td>-0.045628</td>\n",
              "      <td>-0.117548</td>\n",
              "      <td>-0.027359</td>\n",
              "      <td>-0.092003</td>\n",
              "      <td>-0.202279</td>\n",
              "      <td>-0.155474</td>\n",
              "      <td>-0.130995</td>\n",
              "      <td>-0.187341</td>\n",
              "      <td>-0.024126</td>\n",
              "      <td>-0.118993</td>\n",
              "      <td>-0.100786</td>\n",
              "      <td>-0.025793</td>\n",
              "      <td>-0.108889</td>\n",
              "      <td>-0.098661</td>\n",
              "      <td>-0.041812</td>\n",
              "      <td>-0.075387</td>\n",
              "      <td>-0.120421</td>\n",
              "      <td>-0.153217</td>\n",
              "      <td>-0.109667</td>\n",
              "      <td>-0.292440</td>\n",
              "      <td>-0.037614</td>\n",
              "      <td>-0.056285</td>\n",
              "      <td>-0.009117</td>\n",
              "      <td>-0.043762</td>\n",
              "      <td>-0.031595</td>\n",
              "      <td>-0.039768</td>\n",
              "      <td>-0.05244</td>\n",
              "      <td>-0.27917</td>\n",
              "      <td>-0.289247</td>\n",
              "      <td>-0.338801</td>\n",
              "      <td>-0.257087</td>\n",
              "      <td>-0.244164</td>\n",
              "      <td>-0.289247</td>\n",
              "      <td>-0.377516</td>\n",
              "      <td>-0.228481</td>\n",
              "      <td>-0.290089</td>\n",
              "      <td>1.527193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6672</td>\n",
              "      <td>1.309214</td>\n",
              "      <td>-0.518234</td>\n",
              "      <td>-0.657630</td>\n",
              "      <td>-0.467367</td>\n",
              "      <td>0.125706</td>\n",
              "      <td>-0.631375</td>\n",
              "      <td>-0.750867</td>\n",
              "      <td>-0.511860</td>\n",
              "      <td>-0.051732</td>\n",
              "      <td>-0.709886</td>\n",
              "      <td>-0.253748</td>\n",
              "      <td>-0.677707</td>\n",
              "      <td>-0.466562</td>\n",
              "      <td>-0.480002</td>\n",
              "      <td>-0.732025</td>\n",
              "      <td>-0.802706</td>\n",
              "      <td>-0.839223</td>\n",
              "      <td>-0.833054</td>\n",
              "      <td>1.095358</td>\n",
              "      <td>0.956663</td>\n",
              "      <td>-0.577874</td>\n",
              "      <td>-0.598610</td>\n",
              "      <td>-1.536467</td>\n",
              "      <td>0.664488</td>\n",
              "      <td>-1.244591</td>\n",
              "      <td>-1.214927</td>\n",
              "      <td>-0.763882</td>\n",
              "      <td>-0.750870</td>\n",
              "      <td>-0.640278</td>\n",
              "      <td>-1.378361</td>\n",
              "      <td>-1.365289</td>\n",
              "      <td>-0.698925</td>\n",
              "      <td>-0.753537</td>\n",
              "      <td>-0.970113</td>\n",
              "      <td>0.607919</td>\n",
              "      <td>0.719573</td>\n",
              "      <td>-0.012893</td>\n",
              "      <td>-0.087294</td>\n",
              "      <td>-0.049994</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054779</td>\n",
              "      <td>-0.038706</td>\n",
              "      <td>-0.119351</td>\n",
              "      <td>-0.045628</td>\n",
              "      <td>-0.117548</td>\n",
              "      <td>-0.027359</td>\n",
              "      <td>-0.092003</td>\n",
              "      <td>-0.202279</td>\n",
              "      <td>-0.155474</td>\n",
              "      <td>-0.130995</td>\n",
              "      <td>-0.187341</td>\n",
              "      <td>-0.024126</td>\n",
              "      <td>-0.118993</td>\n",
              "      <td>-0.100786</td>\n",
              "      <td>-0.025793</td>\n",
              "      <td>-0.108889</td>\n",
              "      <td>-0.098661</td>\n",
              "      <td>-0.041812</td>\n",
              "      <td>-0.075387</td>\n",
              "      <td>-0.120421</td>\n",
              "      <td>-0.153217</td>\n",
              "      <td>-0.109667</td>\n",
              "      <td>3.419508</td>\n",
              "      <td>-0.037614</td>\n",
              "      <td>-0.056285</td>\n",
              "      <td>-0.009117</td>\n",
              "      <td>-0.043762</td>\n",
              "      <td>-0.031595</td>\n",
              "      <td>-0.039768</td>\n",
              "      <td>-0.05244</td>\n",
              "      <td>-0.27917</td>\n",
              "      <td>-0.289247</td>\n",
              "      <td>-0.338801</td>\n",
              "      <td>3.889734</td>\n",
              "      <td>-0.244164</td>\n",
              "      <td>-0.289247</td>\n",
              "      <td>-0.377516</td>\n",
              "      <td>-0.228481</td>\n",
              "      <td>-0.290089</td>\n",
              "      <td>-0.654796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 127 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     id       md1       md2       md3  ...     rf2_6     rf2_7     rf2_8     rf2_9\n",
              "0  3411  2.003680 -0.494787 -0.495820  ...  2.648897 -0.228481 -0.290089 -0.654796\n",
              "1  2177  1.500909 -0.361906 -0.491025  ... -0.377516 -0.228481  3.447216 -0.654796\n",
              "2  8400 -0.264478 -0.818245 -0.777297  ... -0.377516 -0.228481 -0.290089  1.527193\n",
              "3   464  2.003680  2.163904  2.152560  ... -0.377516 -0.228481 -0.290089  1.527193\n",
              "4  6672  1.309214 -0.518234 -0.657630  ... -0.377516 -0.228481 -0.290089 -0.654796\n",
              "\n",
              "[5 rows x 127 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBUeMtV7tzw6"
      },
      "source": [
        "[**Python**] - Mostrar as primeiras 5 linhas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcH-y4amt3gs",
        "outputId": "46229247-1104-4c53-c560-3ff968d48748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cnae2</th>\n",
              "      <th>rf2</th>\n",
              "      <th>md1</th>\n",
              "      <th>md2</th>\n",
              "      <th>md3</th>\n",
              "      <th>md4</th>\n",
              "      <th>md5</th>\n",
              "      <th>md7</th>\n",
              "      <th>md8</th>\n",
              "      <th>md9</th>\n",
              "      <th>md10</th>\n",
              "      <th>md12</th>\n",
              "      <th>mc1</th>\n",
              "      <th>mc3</th>\n",
              "      <th>mc4</th>\n",
              "      <th>ind02</th>\n",
              "      <th>ind03</th>\n",
              "      <th>ind04</th>\n",
              "      <th>ind05</th>\n",
              "      <th>ind06</th>\n",
              "      <th>ind07</th>\n",
              "      <th>ind08</th>\n",
              "      <th>ind12</th>\n",
              "      <th>ind13</th>\n",
              "      <th>ind19</th>\n",
              "      <th>ind20</th>\n",
              "      <th>ind21</th>\n",
              "      <th>ind22</th>\n",
              "      <th>ind23</th>\n",
              "      <th>ind24</th>\n",
              "      <th>ind25</th>\n",
              "      <th>ind26</th>\n",
              "      <th>ind27</th>\n",
              "      <th>ind31</th>\n",
              "      <th>ind32</th>\n",
              "      <th>ind34</th>\n",
              "      <th>ind36</th>\n",
              "      <th>ind37</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "      <td>0.015101</td>\n",
              "      <td>0.011256</td>\n",
              "      <td>0.111095</td>\n",
              "      <td>0.003233</td>\n",
              "      <td>0.003233</td>\n",
              "      <td>0.016366</td>\n",
              "      <td>0.021082</td>\n",
              "      <td>0.004541</td>\n",
              "      <td>0.004541</td>\n",
              "      <td>0.130930</td>\n",
              "      <td>0.003945</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>0.003355</td>\n",
              "      <td>0.0281</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0976</td>\n",
              "      <td>0.0333</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>0.005996</td>\n",
              "      <td>0.019476</td>\n",
              "      <td>0.124770</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010487</td>\n",
              "      <td>0.029214</td>\n",
              "      <td>0.046445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018198</td>\n",
              "      <td>0.138620</td>\n",
              "      <td>0.003186</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.003355</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4167</td>\n",
              "      <td>0.4194</td>\n",
              "      <td>0.7068</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0076</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7625</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.1429</td>\n",
              "      <td>0.2857</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.4444</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>74</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.002902</td>\n",
              "      <td>0.110160</td>\n",
              "      <td>0.002274</td>\n",
              "      <td>0.002274</td>\n",
              "      <td>0.002902</td>\n",
              "      <td>0.020058</td>\n",
              "      <td>0.003131</td>\n",
              "      <td>0.003131</td>\n",
              "      <td>0.130405</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000209</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.014526</td>\n",
              "      <td>0.120351</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014526</td>\n",
              "      <td>0.032017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138620</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2309</td>\n",
              "      <td>0.2309</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.1785</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000191</td>\n",
              "      <td>0.004042</td>\n",
              "      <td>0.111078</td>\n",
              "      <td>0.001121</td>\n",
              "      <td>0.001121</td>\n",
              "      <td>0.006063</td>\n",
              "      <td>0.023705</td>\n",
              "      <td>0.011886</td>\n",
              "      <td>0.011886</td>\n",
              "      <td>0.131285</td>\n",
              "      <td>0.001925</td>\n",
              "      <td>0.003121</td>\n",
              "      <td>0.000719</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  cnae2  rf2       md1       md2  ...  ind32  ind34  ind36  ind37  target\n",
              "0   0     86    1  0.015101  0.011256  ...    0.0    0.0    1.0    1.0       1\n",
              "1   1     18    9  0.005996  0.019476  ...    0.0    1.0    1.0    0.0       0\n",
              "2   2     74    9  0.000006  0.002902  ...    1.0    1.0    1.0    1.0       0\n",
              "3   3     49    4  0.000009  0.014526  ...    0.0    0.0    0.0    1.0       0\n",
              "4   4     47    1  0.000191  0.004042  ...    0.0    0.0    0.0    0.0       0\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSa161sPLcAw"
      },
      "source": [
        "### Pré-processamento e transformação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiO_F95jc1_s"
      },
      "source": [
        "[**Python**] - Normalizar os dados - StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMTIn6Zf5LlU"
      },
      "source": [
        "df_y = df_X['target']\n",
        "df_X = df_X.drop(columns= ['target','id'])\n"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwJyrlyhKXr6"
      },
      "source": [
        "X_test = df_test.drop(columns= ['id'])"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V1MLO5m8lrm"
      },
      "source": [
        "df_corr = pd.DataFrame([[0,0]])"
      ],
      "execution_count": 513,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKxUQCjP5RK-"
      },
      "source": [
        "\n",
        "for i in df_train.columns:\n",
        "  corr = abs(pd.to_numeric(df_train[i].corr(df_train['target'])))\n",
        "  df_corr = df_corr.append(pd.DataFrame([[i,corr]]))\n",
        "  #print(i,df_train[i].corr(df_train['target']))"
      ],
      "execution_count": 514,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsRJoP2V9OMW"
      },
      "source": [
        "df_corr.rename_axis(columns ={'0':'feature','1':'corr'],inplace=True)"
      ],
      "execution_count": 502,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7791SjuN-XeJ",
        "outputId": "2a233ffc-083b-47a2-8058-b27459bb302b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df_corr.sort_values(by=1,ascending=False).head(50)"
      ],
      "execution_count": 517,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>target</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind32</td>\n",
              "      <td>0.216891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind06</td>\n",
              "      <td>0.210711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind31</td>\n",
              "      <td>0.209753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind03</td>\n",
              "      <td>0.201608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind34</td>\n",
              "      <td>0.200677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mc4</td>\n",
              "      <td>0.191309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind04</td>\n",
              "      <td>0.182885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mc1</td>\n",
              "      <td>0.178358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind05</td>\n",
              "      <td>0.171848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mc3</td>\n",
              "      <td>0.163858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind12</td>\n",
              "      <td>0.156248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind26</td>\n",
              "      <td>0.145761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind27</td>\n",
              "      <td>0.144932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>md5</td>\n",
              "      <td>0.126348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind36</td>\n",
              "      <td>0.123576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind13</td>\n",
              "      <td>0.122380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind19</td>\n",
              "      <td>0.121433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>md10</td>\n",
              "      <td>0.116139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind08</td>\n",
              "      <td>0.103157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind21</td>\n",
              "      <td>0.100595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind20</td>\n",
              "      <td>0.096497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind25</td>\n",
              "      <td>0.095200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind22</td>\n",
              "      <td>0.094291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind23</td>\n",
              "      <td>0.093237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind24</td>\n",
              "      <td>0.091845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>md9</td>\n",
              "      <td>0.091421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>md4</td>\n",
              "      <td>0.090772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>md7</td>\n",
              "      <td>0.077578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind07</td>\n",
              "      <td>0.070897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>md2</td>\n",
              "      <td>0.070350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>md1</td>\n",
              "      <td>0.067123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>md8</td>\n",
              "      <td>0.063947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ind37</td>\n",
              "      <td>0.057841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>md3</td>\n",
              "      <td>0.052318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnae2_43</td>\n",
              "      <td>0.042548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rf2_9</td>\n",
              "      <td>0.039397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnae2_69</td>\n",
              "      <td>0.037880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rf2_8</td>\n",
              "      <td>0.037555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rf2_2</td>\n",
              "      <td>0.036979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnae2_64</td>\n",
              "      <td>0.036714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnae2_68</td>\n",
              "      <td>0.031447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnae2_8</td>\n",
              "      <td>0.027235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnae2_26</td>\n",
              "      <td>0.025489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnae2_21</td>\n",
              "      <td>0.024352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnae2_35</td>\n",
              "      <td>0.024267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnae2_86</td>\n",
              "      <td>0.022201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnae2_80</td>\n",
              "      <td>0.022131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnae2_20</td>\n",
              "      <td>0.021418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cnae2_77</td>\n",
              "      <td>0.019686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1\n",
              "0    target  1.000000\n",
              "0     ind32  0.216891\n",
              "0     ind06  0.210711\n",
              "0     ind31  0.209753\n",
              "0     ind03  0.201608\n",
              "0     ind34  0.200677\n",
              "0       mc4  0.191309\n",
              "0     ind04  0.182885\n",
              "0       mc1  0.178358\n",
              "0     ind05  0.171848\n",
              "0       mc3  0.163858\n",
              "0     ind12  0.156248\n",
              "0     ind26  0.145761\n",
              "0     ind27  0.144932\n",
              "0       md5  0.126348\n",
              "0     ind36  0.123576\n",
              "0     ind13  0.122380\n",
              "0     ind19  0.121433\n",
              "0      md10  0.116139\n",
              "0     ind08  0.103157\n",
              "0     ind21  0.100595\n",
              "0     ind20  0.096497\n",
              "0     ind25  0.095200\n",
              "0     ind22  0.094291\n",
              "0     ind23  0.093237\n",
              "0     ind24  0.091845\n",
              "0       md9  0.091421\n",
              "0       md4  0.090772\n",
              "0       md7  0.077578\n",
              "0     ind07  0.070897\n",
              "0       md2  0.070350\n",
              "0       md1  0.067123\n",
              "0       md8  0.063947\n",
              "0     ind37  0.057841\n",
              "0       md3  0.052318\n",
              "0  cnae2_43  0.042548\n",
              "0     rf2_9  0.039397\n",
              "0  cnae2_69  0.037880\n",
              "0     rf2_8  0.037555\n",
              "0     rf2_2  0.036979\n",
              "0  cnae2_64  0.036714\n",
              "0  cnae2_68  0.031447\n",
              "0   cnae2_8  0.027235\n",
              "0  cnae2_26  0.025489\n",
              "0  cnae2_21  0.024352\n",
              "0  cnae2_35  0.024267\n",
              "0  cnae2_86  0.022201\n",
              "0  cnae2_80  0.022131\n",
              "0  cnae2_20  0.021418\n",
              "0  cnae2_77  0.019686"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 517
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4baPCX36sp_",
        "outputId": "46c9694c-ba1b-45b4-f41e-7e7efcf1f7b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "source": [
        "df_corr.sort_values(by='1')"
      ],
      "execution_count": 498,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-498-8fea10df605a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_corr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   5296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5297\u001b[0m             \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5298\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5300\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '1'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJaJWuUqJCha"
      },
      "source": [
        "### 3. Definir as amostras de treinamento e validação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoO2iEimu4SQ"
      },
      "source": [
        "[**Python**] - Definir as amostras de treinamento e validação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTCdm-F9JBGA",
        "outputId": "f82d49f2-db1a-4e35-c356-6e3e79b708dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_treinamento, X_teste, y_treinamento, y_teste= train_test_split(df_X, df_y, test_size = 0.1)#, random_state = 22091980) #20111974)\n",
        "print(f'X: Treinamento=  {X_treinamento.shape}; X: Teste=  {X_teste.shape}')"
      ],
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X: Treinamento=  (9929, 126); X: Teste=  (1104, 126)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th9CsQpB8VDK",
        "outputId": "acf061d5-7250-4542-fb6d-6c7d08be0db7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f'Y: Treinamento =  {y_treinamento.shape}; Y: Teste = {y_teste.shape}')"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y: Treinamento =  (9929,); Y: Teste = (1104,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bL-vXiULupD"
      },
      "source": [
        "### 4. Definir a arquitetura da Rede Neural com _Tensorflow_/_Keras_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxETX6dTfyU5"
      },
      "source": [
        "[**Python**] - Definir a arquitetura, ou seja:\n",
        "* $N_{I}$: Número de neurônios na camada de entrada (_Input Layer_);\n",
        "* $N_{O}$: Número de neurônios na camada de saída (_Output Layer_);\n",
        "* $N_{H}$: Número de neurônios na camada escondida (_Hidden Layer_);\n",
        "* FA: Função de ativação;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_MdsLicfyU6"
      },
      "source": [
        "# Número de Neurônios na Input Layer:\n",
        "N_I = 126\n",
        "\n",
        "# Número de neurônios na Output Layer:\n",
        "N_O = 1\n",
        "\n",
        "# Número de neurônios na Hidden Layer:\n",
        "N_H = 100\n",
        "\n",
        "N_H2 = 100\n",
        "\n",
        "N_H3=40\n",
        "\n",
        "N_H4 = 40\n",
        "\n",
        "# Função de Ativação da Hidden Layer:\n",
        "#FA_H = tf.nn.leaky_relu\n",
        "FA_H = tf.keras.activations.swish\n",
        "\n",
        "# Função de Ativação da Output Layer:\n",
        "FA_O = tf.keras.activations.sigmoid\n",
        "\n",
        "\n"
      ],
      "execution_count": 469,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUMmDuPCcYyB"
      },
      "source": [
        "[**Python**] - Definir as sementes para NumPy e Tensorflow:\n",
        "> Por questões de reproducibilidade de resultados, use as sementes abaixo:\n",
        "\n",
        "* NumPy: 20111974;\n",
        "* Tensorflow: 20111974;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-echOBmceVy"
      },
      "source": [
        "#np.random.seed(19800922)\n",
        "#tf.random.set_seed(22091980)"
      ],
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZceRRdinEM2"
      },
      "source": [
        "\n",
        "[**Python**] - Definir a Rede Neural:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXQsSYq2DBfI"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "* 1 camada _dropout_ com $p= 0.1$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFR5Kr_nDtD",
        "outputId": "940d7c37-f89a-491d-cca6-5c7668f1dd5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "RN= Sequential()\n",
        "RN.add(Dense(N_H, input_dim= N_I, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dropout(0.05))\n",
        "RN.add(Dense(N_H2, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "RN.add(Dropout(0.05))\n",
        "#RN.add(Dense(N_H3, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "#RN.add(Dropout(0.1))\n",
        "#RN.add(Dense(N_H4, kernel_initializer= tf.keras.initializers.GlorotNormal(), activation= FA_H, kernel_constraint= tf.keras.constraints.UnitNorm()))\n",
        "#RN.add(Dropout(0.1))\n",
        "RN.add(Dense(units= N_O, activation= FA_O))\n",
        "\n",
        "# Resumo da arquitetura da Rede Neural\n",
        "print(RN.summary())"
      ],
      "execution_count": 473,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_297 (Dense)            (None, 100)               12700     \n",
            "_________________________________________________________________\n",
            "dropout_229 (Dropout)        (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_298 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout_230 (Dropout)        (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_299 (Dense)            (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 22,901\n",
            "Trainable params: 22,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JBZf4ypGO8o"
      },
      "source": [
        "### 5. Compilar a Rede Neural\n",
        "\n",
        "Este é um problema de classificação binária (_Male_ ou _Female_). Portanto, temos:\n",
        "* optimizer= tf.keras.optimizers.Adam();\n",
        "* loss=  tf.keras.losses.MeanSquaredError() ou loss= tf.keras.losses.BinaryCrossentropy(). Particularmente, eu gosto de usar loss=  tf.keras.losses.MeanSquaredError() porque o resultado é mais intuitivo;\n",
        "* metrics= tf.keras.metrics.binary_accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USmAuw6f00wL"
      },
      "source": [
        "[**Python**] - Comando modelo.compile(optimizer, loss, metrics):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7KEi1_e6SSF"
      },
      "source": [
        "\n",
        "Algoritmo_Opt = tf.keras.optimizers.Adam()\n",
        "#Algoritmo_Opt = tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.8, beta_2=0.99, epsilon=1e-07 , amsgrad=True,     name='Adam')\n",
        "Loss_Function = tf.keras.losses.MeanSquaredError()\n",
        "Metrics_Perf = tf.keras.metrics.binary_accuracy\n",
        "\n",
        "RN.compile(optimizer = Algoritmo_Opt, loss = Loss_Function, metrics = Metrics_Perf)"
      ],
      "execution_count": 474,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc90EeV_GojX"
      },
      "source": [
        "### 6. Ajustar a Rede Neural\n",
        "\n",
        "Obs.: A opção callbacks abaixo implementa o conceito de _early stopping_. Esta opção vai parar o processo de treinamento da Rede Neural antes de atingirmos o númerco de _epochs_ quando o modelo pára de melhorar, medido pela métrica val_loss. O parâmetro _patience_= k significa que o processo de otimização vai parar se tivermos k _epochs_ consecutivas sem observarmos melhoria da performance da Rede Neural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCCTtUh_vEFP"
      },
      "source": [
        "[**Python**] - Comando modelo.fit(X_treinamento, y_treinamento, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB91J6nrF0db",
        "outputId": "f7e0c9c9-0238-49c3-d845-b56767296642",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "callbacks = [tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10, min_delta = 0.001)]\n",
        "hist= RN.fit(X_treinamento, y_treinamento, epochs = 100, \n",
        "             validation_data = (X_teste, y_teste), \n",
        "             callbacks = callbacks)"
      ],
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1705 - binary_accuracy: 0.7593 - val_loss: 0.1691 - val_binary_accuracy: 0.7672\n",
            "Epoch 2/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1597 - binary_accuracy: 0.7713 - val_loss: 0.1643 - val_binary_accuracy: 0.7672\n",
            "Epoch 3/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1558 - binary_accuracy: 0.7752 - val_loss: 0.1642 - val_binary_accuracy: 0.7717\n",
            "Epoch 4/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1530 - binary_accuracy: 0.7755 - val_loss: 0.1616 - val_binary_accuracy: 0.7772\n",
            "Epoch 5/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1506 - binary_accuracy: 0.7825 - val_loss: 0.1624 - val_binary_accuracy: 0.7663\n",
            "Epoch 6/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1482 - binary_accuracy: 0.7828 - val_loss: 0.1663 - val_binary_accuracy: 0.7645\n",
            "Epoch 7/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1449 - binary_accuracy: 0.7903 - val_loss: 0.1658 - val_binary_accuracy: 0.7645\n",
            "Epoch 8/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1426 - binary_accuracy: 0.7920 - val_loss: 0.1668 - val_binary_accuracy: 0.7672\n",
            "Epoch 9/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1396 - binary_accuracy: 0.7990 - val_loss: 0.1659 - val_binary_accuracy: 0.7536\n",
            "Epoch 10/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1383 - binary_accuracy: 0.8037 - val_loss: 0.1671 - val_binary_accuracy: 0.7636\n",
            "Epoch 11/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1354 - binary_accuracy: 0.8050 - val_loss: 0.1666 - val_binary_accuracy: 0.7690\n",
            "Epoch 12/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1327 - binary_accuracy: 0.8112 - val_loss: 0.1674 - val_binary_accuracy: 0.7726\n",
            "Epoch 13/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1306 - binary_accuracy: 0.8132 - val_loss: 0.1757 - val_binary_accuracy: 0.7500\n",
            "Epoch 14/100\n",
            "311/311 [==============================] - 1s 2ms/step - loss: 0.1284 - binary_accuracy: 0.8171 - val_loss: 0.1712 - val_binary_accuracy: 0.7572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu0kGw_P0gSt",
        "outputId": "6ebb6c51-f53f-4ba8-99a1-8d104db66b4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "RN.weights"
      ],
      "execution_count": 383,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_199/kernel:0' shape=(126, 200) dtype=float32, numpy=\n",
              " array([[-0.109,  0.178, -0.126, ..., -0.059,  0.032,  0.136],\n",
              "        [-0.092,  0.097, -0.124, ...,  0.003, -0.112,  0.075],\n",
              "        [ 0.102, -0.03 ,  0.079, ...,  0.048,  0.035,  0.142],\n",
              "        ...,\n",
              "        [-0.086,  0.064,  0.067, ..., -0.115,  0.152, -0.141],\n",
              "        [-0.028,  0.066, -0.115, ..., -0.086,  0.042,  0.068],\n",
              "        [ 0.057,  0.184, -0.111, ...,  0.057, -0.158, -0.257]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_199/bias:0' shape=(200,) dtype=float32, numpy=\n",
              " array([-0.093, -0.115, -0.084,  0.003, -0.107, -0.072, -0.093, -0.036,\n",
              "        -0.055, -0.082, -0.07 , -0.12 , -0.1  , -0.07 , -0.041, -0.09 ,\n",
              "        -0.169, -0.159, -0.072, -0.111, -0.088, -0.015, -0.014, -0.107,\n",
              "        -0.142, -0.029, -0.167, -0.027, -0.148, -0.098, -0.148, -0.087,\n",
              "        -0.005, -0.073, -0.135, -0.042, -0.038, -0.094, -0.008, -0.032,\n",
              "        -0.04 , -0.084, -0.063, -0.109, -0.124, -0.009, -0.186, -0.044,\n",
              "        -0.092, -0.039, -0.033, -0.064, -0.015, -0.019, -0.103, -0.009,\n",
              "        -0.082, -0.023, -0.054, -0.04 , -0.09 , -0.031, -0.085, -0.09 ,\n",
              "         0.024, -0.082, -0.035, -0.011, -0.087, -0.037, -0.017, -0.137,\n",
              "        -0.016, -0.082, -0.026,  0.015, -0.058, -0.082, -0.077, -0.083,\n",
              "        -0.103, -0.032, -0.044, -0.108, -0.06 , -0.182, -0.015, -0.064,\n",
              "        -0.04 , -0.123, -0.066,  0.006, -0.065, -0.106, -0.073, -0.082,\n",
              "        -0.081, -0.007, -0.044, -0.094, -0.126, -0.033, -0.046, -0.115,\n",
              "        -0.038, -0.078, -0.078, -0.087, -0.013,  0.043, -0.04 ,  0.007,\n",
              "        -0.102, -0.009, -0.07 , -0.155, -0.031,  0.018, -0.033, -0.016,\n",
              "        -0.104, -0.035, -0.056,  0.005, -0.062, -0.085, -0.138, -0.015,\n",
              "        -0.054, -0.07 , -0.034,  0.028, -0.094, -0.033, -0.162, -0.133,\n",
              "        -0.068, -0.096, -0.115, -0.089, -0.095, -0.046, -0.031, -0.174,\n",
              "        -0.023, -0.043, -0.108, -0.043, -0.045, -0.099, -0.114, -0.048,\n",
              "         0.013, -0.011, -0.037, -0.053, -0.05 , -0.063, -0.015, -0.097,\n",
              "        -0.093, -0.072, -0.107,  0.043, -0.031, -0.031, -0.029, -0.073,\n",
              "        -0.061, -0.036, -0.057, -0.042, -0.106, -0.021, -0.04 , -0.049,\n",
              "        -0.078, -0.062, -0.095, -0.067, -0.077, -0.063, -0.097, -0.098,\n",
              "        -0.093, -0.138, -0.144, -0.046, -0.056, -0.065, -0.059, -0.05 ,\n",
              "        -0.104, -0.044, -0.055, -0.074, -0.014, -0.09 , -0.078, -0.092],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_200/kernel:0' shape=(200, 200) dtype=float32, numpy=\n",
              " array([[-0.032,  0.073, -0.008, ..., -0.035,  0.069, -0.01 ],\n",
              "        [-0.028, -0.045, -0.103, ..., -0.039, -0.016, -0.007],\n",
              "        [-0.049,  0.113, -0.029, ...,  0.026,  0.172, -0.076],\n",
              "        ...,\n",
              "        [ 0.003,  0.039,  0.039, ...,  0.135,  0.03 ,  0.026],\n",
              "        [ 0.086, -0.051,  0.041, ..., -0.041,  0.019, -0.079],\n",
              "        [ 0.061,  0.112,  0.04 , ...,  0.019,  0.063,  0.027]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_200/bias:0' shape=(200,) dtype=float32, numpy=\n",
              " array([-0.033,  0.018, -0.034, -0.038,  0.01 , -0.074, -0.059, -0.067,\n",
              "        -0.001, -0.054, -0.004, -0.031, -0.062, -0.038, -0.043, -0.043,\n",
              "        -0.112, -0.017, -0.023, -0.033,  0.02 , -0.027, -0.031, -0.067,\n",
              "         0.024, -0.028, -0.028,  0.029, -0.019, -0.054, -0.043, -0.03 ,\n",
              "        -0.059,  0.003, -0.014, -0.032, -0.046, -0.007, -0.075,  0.049,\n",
              "        -0.116, -0.031, -0.074, -0.012, -0.087, -0.053, -0.062, -0.112,\n",
              "        -0.029, -0.005,  0.039, -0.024,  0.008, -0.063, -0.047, -0.068,\n",
              "        -0.071, -0.048,  0.006,  0.024,  0.031,  0.02 , -0.006,  0.011,\n",
              "        -0.05 ,  0.004, -0.045, -0.031, -0.014,  0.016, -0.014, -0.036,\n",
              "        -0.002, -0.015, -0.031,  0.017,  0.018, -0.045, -0.052, -0.063,\n",
              "        -0.015, -0.064, -0.03 , -0.073, -0.01 , -0.011, -0.036, -0.085,\n",
              "        -0.048, -0.092, -0.01 , -0.001,  0.003, -0.03 , -0.051, -0.065,\n",
              "        -0.128,  0.022, -0.019, -0.105,  0.005, -0.011, -0.087, -0.057,\n",
              "        -0.006,  0.008, -0.081,  0.018, -0.034, -0.092, -0.046,  0.013,\n",
              "        -0.027, -0.014, -0.048, -0.048, -0.015, -0.012, -0.027, -0.052,\n",
              "        -0.03 , -0.033,  0.006,  0.018,  0.007, -0.012, -0.031, -0.063,\n",
              "        -0.05 , -0.068, -0.047, -0.002, -0.032, -0.029, -0.029, -0.021,\n",
              "        -0.053, -0.028, -0.033,  0.038, -0.051, -0.091, -0.029, -0.085,\n",
              "        -0.001, -0.057,  0.025, -0.034, -0.042, -0.052, -0.033, -0.014,\n",
              "        -0.119, -0.067, -0.022, -0.032, -0.058, -0.048, -0.066, -0.041,\n",
              "        -0.001, -0.1  , -0.015, -0.03 , -0.048, -0.071, -0.105,  0.011,\n",
              "        -0.134, -0.035, -0.051, -0.083, -0.024, -0.062,  0.031, -0.028,\n",
              "        -0.064, -0.002,  0.01 , -0.054,  0.015,  0.039, -0.067,  0.007,\n",
              "         0.008,  0.013, -0.075,  0.01 , -0.097, -0.052, -0.061, -0.006,\n",
              "        -0.044, -0.036, -0.032, -0.045, -0.024, -0.024,  0.006, -0.082],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_201/kernel:0' shape=(200, 200) dtype=float32, numpy=\n",
              " array([[ 0.016,  0.031,  0.012, ...,  0.005, -0.027, -0.081],\n",
              "        [ 0.088,  0.057,  0.118, ..., -0.047,  0.001, -0.16 ],\n",
              "        [ 0.052,  0.126,  0.065, ..., -0.074,  0.083, -0.114],\n",
              "        ...,\n",
              "        [ 0.086, -0.015,  0.022, ...,  0.031,  0.098,  0.028],\n",
              "        [ 0.036, -0.109, -0.048, ..., -0.002, -0.111, -0.062],\n",
              "        [ 0.029,  0.092,  0.072, ..., -0.008,  0.063, -0.069]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_201/bias:0' shape=(200,) dtype=float32, numpy=\n",
              " array([ 1.525e-02,  1.602e-02,  2.846e-02, -6.775e-02, -1.027e-01,\n",
              "        -8.623e-02, -4.492e-02, -3.435e-02,  8.323e-05, -5.899e-03,\n",
              "        -3.163e-02,  6.297e-02, -1.663e-02, -8.249e-02, -3.393e-02,\n",
              "        -9.073e-03, -7.360e-02, -5.180e-02,  2.441e-02,  3.801e-02,\n",
              "        -5.318e-02, -1.058e-02, -5.653e-02, -1.637e-02, -8.654e-02,\n",
              "        -1.016e-01, -8.220e-02, -2.622e-02, -7.191e-02, -3.224e-02,\n",
              "        -4.620e-02, -4.575e-02, -1.745e-03,  1.315e-02, -5.236e-02,\n",
              "        -6.933e-02, -5.337e-02, -1.029e-01,  1.096e-02, -1.442e-02,\n",
              "        -7.551e-02,  3.302e-02, -5.496e-02, -1.971e-02,  1.155e-03,\n",
              "         3.263e-02, -2.452e-02,  2.972e-02, -8.779e-02, -7.920e-02,\n",
              "        -5.494e-02, -4.925e-02,  8.322e-03, -7.470e-02, -6.691e-02,\n",
              "        -1.183e-02, -4.538e-02, -7.310e-02, -8.178e-02, -3.843e-03,\n",
              "        -9.234e-02, -3.630e-02, -4.968e-02, -4.935e-02, -3.040e-02,\n",
              "        -3.005e-02,  4.797e-03, -3.380e-02,  3.754e-02, -7.269e-02,\n",
              "        -8.094e-02, -1.176e-01,  1.730e-02, -1.426e-02,  7.494e-03,\n",
              "         1.621e-03, -9.038e-02,  6.725e-03, -4.053e-02, -7.831e-02,\n",
              "         1.221e-02, -7.456e-02, -1.187e-02,  4.422e-03, -7.371e-02,\n",
              "         1.898e-02, -2.018e-02, -4.548e-03,  8.626e-02, -5.698e-02,\n",
              "        -1.009e-01,  2.817e-02, -7.039e-02, -4.749e-02,  9.636e-04,\n",
              "        -2.940e-02, -4.693e-02, -2.138e-02, -5.318e-03, -8.508e-02,\n",
              "        -6.499e-02, -4.680e-02, -8.103e-04,  5.021e-02,  1.627e-02,\n",
              "         1.367e-02, -5.429e-02,  6.088e-02, -5.363e-02, -9.221e-03,\n",
              "         3.780e-02, -1.039e-01,  1.837e-02,  5.184e-02, -3.904e-02,\n",
              "         6.019e-02, -5.074e-02, -9.729e-02,  4.769e-04, -3.021e-03,\n",
              "         3.398e-02,  5.060e-02, -3.152e-02, -7.370e-03,  1.978e-02,\n",
              "        -7.226e-02, -2.645e-02,  1.074e-02, -2.310e-02, -3.973e-02,\n",
              "         2.249e-02,  8.915e-02,  1.033e-02, -4.829e-02,  1.620e-02,\n",
              "        -2.756e-02,  6.661e-02,  2.506e-02, -5.759e-02, -1.360e-02,\n",
              "        -4.346e-02, -1.123e-03, -4.641e-02, -1.269e-02,  1.232e-02,\n",
              "        -3.812e-02, -8.294e-02, -2.365e-02, -7.516e-02, -1.004e-01,\n",
              "         3.536e-02,  2.567e-02, -6.644e-02, -1.696e-02,  1.906e-02,\n",
              "        -6.104e-02, -3.779e-02, -6.229e-02, -4.476e-02, -4.095e-02,\n",
              "        -9.361e-02, -2.532e-02,  2.690e-02,  5.825e-03, -4.073e-02,\n",
              "        -2.229e-02,  4.423e-02,  7.707e-03,  2.798e-02,  2.421e-02,\n",
              "        -8.906e-02, -8.382e-02, -2.647e-02, -1.098e-02, -2.268e-03,\n",
              "         1.762e-03, -5.596e-02, -4.003e-02, -1.035e-01, -2.649e-02,\n",
              "         3.092e-02, -7.076e-02, -3.393e-02,  1.630e-02, -3.042e-02,\n",
              "         1.035e-02, -6.245e-02, -5.230e-02, -7.417e-02,  4.083e-02,\n",
              "        -3.167e-02, -4.067e-02,  3.922e-02,  2.185e-03,  7.778e-02,\n",
              "        -7.294e-02, -6.158e-02, -9.381e-02, -1.524e-02, -5.519e-02],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_202/kernel:0' shape=(200, 200) dtype=float32, numpy=\n",
              " array([[ 0.046, -0.079,  0.047, ..., -0.072,  0.066,  0.117],\n",
              "        [-0.054,  0.054, -0.075, ..., -0.099, -0.023, -0.103],\n",
              "        [-0.074,  0.023,  0.029, ...,  0.024,  0.001,  0.093],\n",
              "        ...,\n",
              "        [ 0.156, -0.059, -0.043, ...,  0.088, -0.061, -0.109],\n",
              "        [-0.093, -0.068, -0.026, ..., -0.091,  0.053, -0.042],\n",
              "        [ 0.071,  0.025,  0.001, ...,  0.156, -0.01 , -0.072]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_202/bias:0' shape=(200,) dtype=float32, numpy=\n",
              " array([ 0.036,  0.028, -0.106, -0.059,  0.036, -0.057,  0.028,  0.025,\n",
              "        -0.064, -0.028, -0.049,  0.03 , -0.098, -0.105, -0.075, -0.075,\n",
              "        -0.068,  0.059, -0.102,  0.025, -0.04 , -0.09 ,  0.066, -0.061,\n",
              "        -0.065,  0.067,  0.033, -0.139,  0.044, -0.106, -0.111,  0.028,\n",
              "         0.025,  0.025, -0.061, -0.083, -0.123, -0.122,  0.054,  0.058,\n",
              "        -0.037, -0.088, -0.078, -0.078,  0.061, -0.044, -0.068, -0.039,\n",
              "         0.007,  0.038,  0.034,  0.019, -0.077,  0.045,  0.048,  0.017,\n",
              "        -0.118,  0.039, -0.063,  0.011,  0.042, -0.077, -0.004, -0.128,\n",
              "        -0.069, -0.034, -0.06 , -0.029,  0.064,  0.007, -0.083,  0.032,\n",
              "        -0.039,  0.037,  0.034, -0.032, -0.1  , -0.088, -0.089,  0.02 ,\n",
              "        -0.07 ,  0.013,  0.045,  0.044, -0.114, -0.063,  0.016,  0.039,\n",
              "         0.028, -0.04 , -0.077, -0.097, -0.047,  0.041,  0.031, -0.093,\n",
              "        -0.077, -0.019, -0.062, -0.061, -0.075, -0.064,  0.012, -0.098,\n",
              "        -0.102,  0.042,  0.037, -0.027,  0.03 , -0.036, -0.069,  0.044,\n",
              "        -0.057,  0.03 , -0.014,  0.035,  0.004,  0.047, -0.035, -0.007,\n",
              "        -0.065, -0.069,  0.064, -0.043,  0.065, -0.02 , -0.059,  0.036,\n",
              "        -0.055, -0.009,  0.047, -0.011, -0.088, -0.045, -0.078, -0.058,\n",
              "         0.031, -0.039,  0.023,  0.023,  0.03 , -0.11 , -0.073,  0.017,\n",
              "        -0.025, -0.078, -0.071,  0.046, -0.095,  0.081, -0.057, -0.069,\n",
              "         0.051, -0.051,  0.064,  0.001,  0.013,  0.028,  0.009,  0.02 ,\n",
              "        -0.066, -0.042,  0.009,  0.052, -0.029,  0.047, -0.081,  0.019,\n",
              "        -0.125, -0.037,  0.029, -0.046, -0.083, -0.096, -0.094, -0.069,\n",
              "        -0.133, -0.059,  0.048,  0.048,  0.035, -0.079,  0.024,  0.013,\n",
              "        -0.02 , -0.071, -0.082, -0.03 , -0.061,  0.036,  0.039, -0.075,\n",
              "         0.038,  0.017, -0.064, -0.01 ,  0.068, -0.074,  0.039,  0.066],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_203/kernel:0' shape=(200, 1) dtype=float32, numpy=\n",
              " array([[-0.014],\n",
              "        [ 0.007],\n",
              "        [-0.006],\n",
              "        [-0.006],\n",
              "        [-0.   ],\n",
              "        [ 0.019],\n",
              "        [-0.045],\n",
              "        [ 0.001],\n",
              "        [ 0.092],\n",
              "        [-0.006],\n",
              "        [ 0.009],\n",
              "        [-0.061],\n",
              "        [ 0.043],\n",
              "        [ 0.112],\n",
              "        [ 0.047],\n",
              "        [ 0.03 ],\n",
              "        [ 0.016],\n",
              "        [-0.059],\n",
              "        [ 0.012],\n",
              "        [ 0.007],\n",
              "        [ 0.007],\n",
              "        [ 0.054],\n",
              "        [-0.008],\n",
              "        [ 0.006],\n",
              "        [ 0.018],\n",
              "        [-0.072],\n",
              "        [-0.003],\n",
              "        [ 0.028],\n",
              "        [-0.036],\n",
              "        [ 0.078],\n",
              "        [ 0.065],\n",
              "        [ 0.003],\n",
              "        [-0.004],\n",
              "        [-0.006],\n",
              "        [ 0.002],\n",
              "        [ 0.128],\n",
              "        [ 0.11 ],\n",
              "        [ 0.077],\n",
              "        [-0.025],\n",
              "        [-0.055],\n",
              "        [ 0.005],\n",
              "        [ 0.049],\n",
              "        [ 0.08 ],\n",
              "        [ 0.058],\n",
              "        [-0.052],\n",
              "        [ 0.022],\n",
              "        [ 0.026],\n",
              "        [ 0.001],\n",
              "        [-0.003],\n",
              "        [ 0.005],\n",
              "        [ 0.002],\n",
              "        [ 0.003],\n",
              "        [ 0.021],\n",
              "        [ 0.01 ],\n",
              "        [-0.053],\n",
              "        [-0.014],\n",
              "        [ 0.09 ],\n",
              "        [-0.008],\n",
              "        [ 0.003],\n",
              "        [ 0.002],\n",
              "        [-0.067],\n",
              "        [ 0.023],\n",
              "        [ 0.002],\n",
              "        [ 0.058],\n",
              "        [ 0.038],\n",
              "        [ 0.001],\n",
              "        [-0.003],\n",
              "        [-0.007],\n",
              "        [-0.02 ],\n",
              "        [-0.027],\n",
              "        [ 0.105],\n",
              "        [-0.022],\n",
              "        [-0.005],\n",
              "        [-0.027],\n",
              "        [-0.021],\n",
              "        [ 0.011],\n",
              "        [ 0.074],\n",
              "        [ 0.054],\n",
              "        [ 0.014],\n",
              "        [-0.047],\n",
              "        [ 0.036],\n",
              "        [ 0.005],\n",
              "        [-0.024],\n",
              "        [-0.007],\n",
              "        [ 0.088],\n",
              "        [ 0.085],\n",
              "        [ 0.   ],\n",
              "        [-0.012],\n",
              "        [ 0.002],\n",
              "        [-0.006],\n",
              "        [ 0.014],\n",
              "        [ 0.038],\n",
              "        [ 0.023],\n",
              "        [ 0.007],\n",
              "        [-0.007],\n",
              "        [ 0.072],\n",
              "        [ 0.009],\n",
              "        [-0.012],\n",
              "        [ 0.009],\n",
              "        [ 0.002],\n",
              "        [ 0.009],\n",
              "        [ 0.004],\n",
              "        [-0.027],\n",
              "        [ 0.065],\n",
              "        [ 0.126],\n",
              "        [-0.025],\n",
              "        [-0.006],\n",
              "        [-0.001],\n",
              "        [-0.003],\n",
              "        [-0.008],\n",
              "        [-0.002],\n",
              "        [-0.03 ],\n",
              "        [ 0.009],\n",
              "        [-0.044],\n",
              "        [-0.008],\n",
              "        [-0.022],\n",
              "        [-0.051],\n",
              "        [-0.032],\n",
              "        [ 0.002],\n",
              "        [ 0.017],\n",
              "        [ 0.059],\n",
              "        [ 0.02 ],\n",
              "        [-0.038],\n",
              "        [-0.001],\n",
              "        [-0.019],\n",
              "        [ 0.02 ],\n",
              "        [ 0.004],\n",
              "        [-0.011],\n",
              "        [-0.001],\n",
              "        [-0.007],\n",
              "        [-0.003],\n",
              "        [-0.016],\n",
              "        [ 0.088],\n",
              "        [ 0.026],\n",
              "        [-0.002],\n",
              "        [-0.003],\n",
              "        [-0.039],\n",
              "        [-0.006],\n",
              "        [-0.034],\n",
              "        [-0.023],\n",
              "        [ 0.   ],\n",
              "        [ 0.134],\n",
              "        [ 0.074],\n",
              "        [-0.004],\n",
              "        [ 0.006],\n",
              "        [ 0.082],\n",
              "        [ 0.01 ],\n",
              "        [-0.029],\n",
              "        [ 0.031],\n",
              "        [-0.034],\n",
              "        [ 0.011],\n",
              "        [-0.   ],\n",
              "        [-0.021],\n",
              "        [ 0.004],\n",
              "        [-0.027],\n",
              "        [ 0.003],\n",
              "        [-0.006],\n",
              "        [-0.005],\n",
              "        [ 0.005],\n",
              "        [-0.003],\n",
              "        [ 0.092],\n",
              "        [-0.005],\n",
              "        [-0.01 ],\n",
              "        [ 0.011],\n",
              "        [-0.005],\n",
              "        [-0.003],\n",
              "        [ 0.033],\n",
              "        [-0.036],\n",
              "        [ 0.057],\n",
              "        [-0.011],\n",
              "        [-0.004],\n",
              "        [-0.008],\n",
              "        [ 0.05 ],\n",
              "        [ 0.015],\n",
              "        [ 0.043],\n",
              "        [ 0.032],\n",
              "        [ 0.088],\n",
              "        [ 0.021],\n",
              "        [-0.032],\n",
              "        [-0.066],\n",
              "        [-0.017],\n",
              "        [ 0.025],\n",
              "        [-0.005],\n",
              "        [-0.034],\n",
              "        [ 0.015],\n",
              "        [ 0.071],\n",
              "        [ 0.049],\n",
              "        [-0.002],\n",
              "        [-0.004],\n",
              "        [-0.036],\n",
              "        [ 0.006],\n",
              "        [ 0.019],\n",
              "        [-0.034],\n",
              "        [-0.008],\n",
              "        [ 0.   ],\n",
              "        [ 0.002],\n",
              "        [-0.037],\n",
              "        [ 0.002],\n",
              "        [-0.029],\n",
              "        [-0.054]], dtype=float32)>,\n",
              " <tf.Variable 'dense_203/bias:0' shape=(1,) dtype=float32, numpy=array([-0.084], dtype=float32)>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 383
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9LNgeg6ci5u"
      },
      "source": [
        "def Model_Loss(hist):\n",
        "    print(hist.history.keys())\n",
        "    plt.plot(hist.history('loss'))\n",
        "    plt.plot(hist.history('val_loss'))\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend(['Training', 'Validation'], loc= 'upper right')\n",
        "    plt.show()\n",
        "\n",
        "def Model_Accuracy(hist):\n",
        "    print(hist.history.keys())\n",
        "    plt.plot(hist.history('accuracy'))\n",
        "    plt.plot(hist.history('val_accuracy'))\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend(['Training', 'Validation'], loc= 'upper right')\n",
        "    plt.show()\n",
        "\n",
        "def Model_MSE(hist):\n",
        "    print(hist.history.keys())\n",
        "    plt.plot(hist.history('mse'))\n",
        "    plt.plot(hist.history('val_mse'))\n",
        "    plt.title('Model MSE')\n",
        "    plt.ylabel('MSE')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend(['Training', 'Validation'], loc= 'upper right')\n",
        "    plt.show()\n",
        "\n",
        "def Mostra_ConfusionMatrix():\n",
        "    y_pred = RN.predict_classes(X_teste)\n",
        "    mc = confusion_matrix(y_teste, y_pred)\n",
        "    #sns.heatmap(mc,annot=True, annot_kws={\"size\": 10},fmt=\"d\")\n",
        "    sns.heatmap(mc/np.sum(mc), annot=True, annot_kws={\"size\": 10}, fmt='.2%', cmap='Blues')"
      ],
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71mX1iwvHMc5",
        "outputId": "20f98996-eb1d-440d-de67-a71402631613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "Model_Accuracy(hist)\n",
        "hist.history()"
      ],
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-378-52181b2ceb01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mModel_Accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-377-0ec53de5d63e>\u001b[0m in \u001b[0;36mModel_Accuracy\u001b[0;34m(hist)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mModel_Accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-zJ6GIjHbY8",
        "outputId": "53d8490e-7b98-4831-eef3-63fb5e9bbccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "Model_Loss(hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-8a9781df17aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mModel_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Model_Loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1sL_DTrKmpq"
      },
      "source": [
        "### 7. Avaliar a performance da Rede Neural\n",
        "\n",
        "Para avaliar a a Rede Neural, simplesmente informamos as amostras de teste: X_teste e y_teste. A função evaluate() vai retornar uma lista contendo 2 valores: loss e accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VckQfEFPvMa7"
      },
      "source": [
        "[**Python**] - Comando modelo.evaluate(X_teste, y_teste)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUhEiqxfKmpv",
        "outputId": "e1d505c9-d953-4ddd-9847-72fe79820fed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "RN.evaluate(X_teste, y_teste)"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 1ms/step - loss: 0.1648 - binary_accuracy: 0.7572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16479942202568054, 0.7572463750839233]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 370
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiM_zEX6epou",
        "outputId": "137f5d67-91c9-40c1-d3b4-f9a642527364",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "RN.evaluate(df_X, df_y)"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "345/345 [==============================] - 0s 1ms/step - loss: 0.1276 - binary_accuracy: 0.8214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12761256098747253, 0.8214447498321533]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5YwW5PCud3o",
        "outputId": "1edfda33-37a0-4a3f-c2c6-d9aafcaa8acc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "RN.evaluate(X_treinamento, y_treinamento)"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "311/311 [==============================] - 0s 1ms/step - loss: 0.1235 - binary_accuracy: 0.8286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12347785383462906, 0.8285829424858093]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P4ezHNQyRvh",
        "outputId": "bf5344d2-fae2-4583-ee30-36e38e61f7eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hist.params "
      ],
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epochs': 100, 'steps': 311, 'verbose': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agO4cGTqKmpz"
      },
      "source": [
        "A seguir, a matriz de confusão:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdiMhkVyaCDS"
      },
      "source": [
        "def Mostra_ConfusionMatrix():\n",
        "    y_pred = RN.predict_classes(X_teste)\n",
        "    mc = confusion_matrix(y_teste, y_pred)\n",
        "    #sns.heatmap(mc,annot=True, annot_kws={\"size\": 10},fmt=\"d\")\n",
        "    sns.heatmap(mc/np.sum(mc), annot=True, annot_kws={\"size\": 10}, fmt='.2%', cmap='Blues')"
      ],
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLIAXu7SN7pV",
        "outputId": "fe3904ec-a58e-458d-dc31-37b05cb99129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "Mostra_ConfusionMatrix()"
      ],
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5zYHcGuMPZe"
      },
      "source": [
        "### 8. _Fine tuning_ da Rede Neural\n",
        "\n",
        "Para aumentar a acurácia da Rede Neural, sugiro aumentarmos o número de neurônios na _Hidden Layer_ e/ou aumentar o número de _Hidden Layers_.\n",
        "\n",
        "No entanto, obtivemos uma acurácia razoável com a Rede Neural _baseline_. Portanto, deixo como exercício para os alunos o desafio de melhorar a acurácia desta Rede Neural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ISodOu-Kmp3"
      },
      "source": [
        "### 9. Fazer Predições com a Rede Neural"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xgdL1W4vUrN"
      },
      "source": [
        "[**Python**] - Comando:\n",
        "* RN.predict_classes(X_treinamento);\n",
        "* RN.predict_classes(X_teste)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqy2rt3YfPiy"
      },
      "source": [
        "y_test = RN.predict_classes(X_test)\n",
        "\n",
        "df_submit = pd.concat([df_test['id'],pd.DataFrame(y_test,columns=['target']).astype('boolean')],axis=1)\n",
        "\n",
        "df_submit.to_csv('/PyLadies_NL_12.csv',index = False, sep = ',')"
      ],
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C_u02mygKgt"
      },
      "source": [
        ""
      ],
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU_6XlFRgPL2",
        "outputId": "e82e828c-944f-4ea9-eff0-e7f43a220660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_submit['target'].value_counts()"
      ],
      "execution_count": 355,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    861\n",
              "True     139\n",
              "Name: target, dtype: Int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 355
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvywP0nZMtA-"
      },
      "source": [
        "### 10. Conclusões\n",
        "\n",
        "Desenvolvemos uma Rede Neural capaz de identificar Sexo (_Gender_) com acurácia= 0.9120."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL2g2pn-RfJi"
      },
      "source": [
        ""
      ],
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpufntZjyH8T"
      },
      "source": [
        "### Salvar a Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKqn0leTyLOy"
      },
      "source": [
        "# Save the weights\n",
        "RN.save('/RN_12.h5')"
      ],
      "execution_count": 354,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viORp6XjrC66"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}